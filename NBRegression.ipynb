{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB Regression with PyTorch\n",
    "\n",
    "Negative binomial regression is in fact a 1-layer neural network with a special loss function. Here we increase the number of layers so that the mean $\\mu$ of the negative binomial distribution is no longer approximated by a purely linear combination of the features. At the same time, we also regress the dispersion $\\alpha$ which determines the variance ($\\mu+\\alpha\\muÂ²$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from NBPyTorch import NBNet, PoNet, NBNLLLoss\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from util import MyUtil\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "util=MyUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(muA,alphaA,muB,alphaB):\n",
    "    return muA.data.numpy(),alphaA.data.numpy(),muB.data.numpy(),alphaB.data.numpy()\n",
    "\n",
    "# Encode gametype\n",
    "rounds = {\n",
    "    \"Finale\": 1,\n",
    "    \"Spiel um Platz Drei\": 2,\n",
    "    \"Halbfinale\": 3,\n",
    "    \"Viertelfinale\": 4,\n",
    "    \"Achtelfinale\": 5,\n",
    "    \"Gruppenphase\": 6\n",
    "}\n",
    "def map_to_round(x):\n",
    "    if x.startswith(\"Gruppe\"):\n",
    "        return rounds[\"Gruppenphase\"]\n",
    "    else:\n",
    "        return rounds[x]\n",
    "\n",
    "def scale(data,state):\n",
    "    data[\"teamA_def_val\"]=(data[\"teamA_def_val\"]-state[\"teamA_def_mean\"])/state[\"teamA_def_std\"]\n",
    "    data[\"teamA_off_val\"]=(data[\"teamA_off_val\"]-state[\"teamA_off_mean\"])/state[\"teamA_off_std\"]\n",
    "    data[\"teamB_def_val\"]=(data[\"teamB_def_val\"]-state[\"teamB_def_mean\"])/state[\"teamB_def_std\"]\n",
    "    data[\"teamB_off_val\"]=(data[\"teamB_off_val\"]-state[\"teamB_off_mean\"])/state[\"teamB_off_std\"]\n",
    "    data[\"teamA_frag\"]=(data[\"teamA_frag\"]-state[\"teamA_frag_mean\"])/state[\"teamA_frag_std\"]\n",
    "    data[\"teamB_frag\"]=(data[\"teamB_frag\"]-state[\"teamB_frag_mean\"])/state[\"teamB_frag_std\"]\n",
    "    data[\"teamA_age\"]=(data[\"teamA_age\"]-state[\"teamA_age_mean\"])/state[\"teamA_age_std\"]\n",
    "    data[\"teamB_age\"]=(data[\"teamB_age\"]-state[\"teamB_age_mean\"])/state[\"teamB_age_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/final.csv: past tournaments\n",
    "#data = pd.read_csv(filepath_or_buffer=\"data/final.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "# data/final_w_18: updated with WC 2018 results as the tournament progressed\n",
    "data = pd.read_csv(filepath_or_buffer=\"data/final_w_18.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "\n",
    "# impute missing past values with 0\n",
    "data.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "# drop id columns\n",
    "data.drop([\"gameid\",\"teamidA\",\"teamidB\"],axis=1,inplace=True)\n",
    "\n",
    "# Encode gametype\n",
    "rounds = {\n",
    "    \"Finale\": 1,\n",
    "    \"Spiel um Platz Drei\": 2,\n",
    "    \"Halbfinale\": 3,\n",
    "    \"Viertelfinale\": 4,\n",
    "    \"Achtelfinale\": 5,\n",
    "    \"Gruppenphase\": 6\n",
    "}\n",
    "def map_to_round(x):\n",
    "    if x.startswith(\"Gruppe\"):\n",
    "        return rounds[\"Gruppenphase\"]\n",
    "    else:\n",
    "        return rounds[x]\n",
    "\n",
    "data[\"gametype\"]=data[\"gametype\"].apply(map_to_round)\n",
    "#data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knockout stage w/o pens\n",
    "data_ko=data.drop(data[data.gametype == 6].index,axis=0).copy()\n",
    "data_ko.drop(data_ko[data_ko.addinfo == 'n.E.'].index,axis=0,inplace=True) # drop pens\n",
    "\n",
    "# group stage \n",
    "data_gr=data.drop(data[data.gametype != 6].index,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knockout stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ko.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_ko.copy(),test_size=0.2)\n",
    "col=[\"gametype\",\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamA_def_mean = data_train[\"teamA_def_val\"].mean()\n",
    "teamA_def_std = data_train[\"teamA_def_val\"].std()\n",
    "teamA_off_mean = data_train[\"teamA_off_val\"].mean()\n",
    "teamA_off_std = data_train[\"teamA_off_val\"].std()\n",
    "\n",
    "teamB_def_mean = data_train[\"teamB_def_val\"].mean()\n",
    "teamB_def_std = data_train[\"teamB_def_val\"].std()\n",
    "teamB_off_mean = data_train[\"teamB_off_val\"].mean()\n",
    "teamB_off_std = data_train[\"teamB_off_val\"].std()\n",
    "\n",
    "teamA_frag_mean = data_train[\"teamA_frag\"].mean()\n",
    "teamA_frag_std = data_train[\"teamA_frag\"].std()\n",
    "\n",
    "teamB_frag_mean = data_train[\"teamB_frag\"].mean()\n",
    "teamB_frag_std = data_train[\"teamB_frag\"].std()\n",
    "\n",
    "teamA_age_mean = data_train[\"teamA_age\"].mean()\n",
    "teamA_age_std = data_train[\"teamA_age\"].std()\n",
    "\n",
    "teamB_age_mean = data_train[\"teamB_age\"].mean()\n",
    "teamB_age_std = data_train[\"teamB_age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train features\n",
    "data_train[\"teamA_def_val\"]=(data_train[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_train[\"teamA_off_val\"]=(data_train[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_train[\"teamB_def_val\"]=(data_train[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_train[\"teamB_off_val\"]=(data_train[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_train[\"teamA_frag\"]=(data_train[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_train[\"teamB_frag\"]=(data_train[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_train[\"teamA_age\"]=(data_train[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_train[\"teamB_age\"]=(data_train[\"teamB_age\"]-teamB_age_mean)/teamB_age_std\n",
    "\n",
    "# scale test features\n",
    "data_test[\"teamA_def_val\"]=(data_test[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_test[\"teamA_off_val\"]=(data_test[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_test[\"teamB_def_val\"]=(data_test[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_test[\"teamB_off_val\"]=(data_test[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_test[\"teamA_frag\"]=(data_test[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_test[\"teamB_frag\"]=(data_test[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_test[\"teamA_age\"]=(data_test[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_test[\"teamB_age\"]=(data_test[\"teamB_age\"]-teamB_age_mean)/teamB_age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = torch.from_numpy(X_train).float()\n",
    "y_trA = torch.from_numpy(y_train[:,[0]]).float()\n",
    "y_trB = torch.from_numpy(y_train[:,[1]]).float()\n",
    "X_te = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = NBNLLLoss(eps=1e-3)\n",
    "def fn_print(module, grad_input, grad_output):\n",
    "    print(\"Gradients Input\",grad_input)\n",
    "    print(\"Gradients Output\", grad_output)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = NBNet(len(col),30,20,4,0.3)\n",
    "optimizer = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural.train()\n",
    "    muA,alphaA,muB,alphaB = neural(X_tr)\n",
    "    lossA = crit(muA,alphaA,y_trA)\n",
    "    lossB = crit(muB,alphaB,y_trB)\n",
    "    loss = lossA+lossB\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_tr = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_train)\n",
    "    # update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # evaluate\n",
    "    neural.eval()\n",
    "    muA,alphaA,muB,alphaB = neural(X_te)\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_val = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_test)\n",
    "    print(epoch,loss.item(),tend_acc_tr,tend_acc_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural.eval()\n",
    "muA,alphaA,muB,alphaB=neural(X_te)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"teamA_def_mean\": teamA_def_mean,\n",
    "    \"teamA_def_std\": teamA_def_std,\n",
    "    \"teamA_off_mean\": teamA_off_mean,\n",
    "    \"teamA_off_std\": teamA_off_std,\n",
    "    \"teamB_def_mean\": teamB_def_mean,\n",
    "    \"teamB_def_std\": teamB_def_std,\n",
    "    \"teamB_off_mean\": teamB_off_mean,\n",
    "    \"teamB_off_std\": teamB_off_std,\n",
    "    \"teamA_frag_mean\": teamA_frag_mean, \n",
    "    \"teamA_frag_std\": teamA_frag_std,\n",
    "    \"teamB_frag_mean\": teamB_frag_mean, \n",
    "    \"teamB_frag_std\": teamB_frag_std,\n",
    "    \"teamA_age_mean\": teamA_age_mean, \n",
    "    \"teamA_age_std\": teamA_age_std,\n",
    "    \"teamB_age_mean\": teamB_age_mean,\n",
    "    \"teamB_age_std\": teamB_age_std,\n",
    "    \"state_dict\": neural.state_dict(),\n",
    "}\n",
    "#torch.save(state, 'model/model_ko.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_pois = torch.nn.PoissonNLLLoss()\n",
    "neural_pois = PoNet(len(col),30,20,2,0.2)\n",
    "optimizer_pois = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural_pois.train()\n",
    "    mu = neural_pois(X_tr)\n",
    "    lossA_pois = crit_pois(mu[:,[0]],y_trA)\n",
    "    lossB_pois = crit_pois(mu[:,[1]],y_trB)\n",
    "    loss_pois = lossA_pois+lossB_pois    \n",
    "    tend_acc_tr = util.tend_acc_pois(mu.data.numpy(),y_train)\n",
    "    # evaluate\n",
    "    neural_pois.eval()\n",
    "    mu = neural_pois(X_te)\n",
    "    tend_acc_val = util.tend_acc_pois(mu.data.numpy(),y_test)\n",
    "    print(epoch, loss_pois.item(),tend_acc_tr,tend_acc_val)\n",
    "    # update\n",
    "    optimizer_pois.zero_grad()\n",
    "    loss_pois.backward()\n",
    "    optimizer_pois.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pois.eval()\n",
    "mu=neural_pois(X_te).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=util.calc_pois_probs(mu[:,0],mu[:,1])\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Poisson regression suffers from the same problem as negative binomial regression with fixed dispersion $\\alpha$ (it seems to memorize the most frequent outcomes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_gr.copy(),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamA_def_mean = data_train[\"teamA_def_val\"].mean()\n",
    "teamA_def_std = data_train[\"teamA_def_val\"].std()\n",
    "teamA_off_mean = data_train[\"teamA_off_val\"].mean()\n",
    "teamA_off_std = data_train[\"teamA_off_val\"].std()\n",
    "\n",
    "teamB_def_mean = data_train[\"teamB_def_val\"].mean()\n",
    "teamB_def_std = data_train[\"teamB_def_val\"].std()\n",
    "teamB_off_mean = data_train[\"teamB_off_val\"].mean()\n",
    "teamB_off_std = data_train[\"teamB_off_val\"].std()\n",
    "\n",
    "teamA_frag_mean = data_train[\"teamA_frag\"].mean()\n",
    "teamA_frag_std = data_train[\"teamA_frag\"].std()\n",
    "\n",
    "teamB_frag_mean = data_train[\"teamB_frag\"].mean()\n",
    "teamB_frag_std = data_train[\"teamB_frag\"].std()\n",
    "\n",
    "teamA_age_mean = data_train[\"teamA_age\"].mean()\n",
    "teamA_age_std = data_train[\"teamA_age\"].std()\n",
    "\n",
    "teamB_age_mean = data_train[\"teamB_age\"].mean()\n",
    "teamB_age_std = data_train[\"teamB_age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale some features\n",
    "data_train[\"teamA_def_val\"]=(data_train[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_train[\"teamA_off_val\"]=(data_train[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_train[\"teamB_def_val\"]=(data_train[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_train[\"teamB_off_val\"]=(data_train[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_train[\"teamA_frag\"]=(data_train[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_train[\"teamB_frag\"]=(data_train[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_train[\"teamA_age\"]=(data_train[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_train[\"teamB_age\"]=(data_train[\"teamB_age\"]-teamB_age_mean)/teamB_age_std\n",
    "\n",
    "# scale test features\n",
    "data_test[\"teamA_def_val\"]=(data_test[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_test[\"teamA_off_val\"]=(data_test[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_test[\"teamB_def_val\"]=(data_test[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_test[\"teamB_off_val\"]=(data_test[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_test[\"teamA_frag\"]=(data_test[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_test[\"teamB_frag\"]=(data_test[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_test[\"teamA_age\"]=(data_test[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_test[\"teamB_age\"]=(data_test[\"teamB_age\"]-teamB_age_mean)/teamB_age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]\n",
    "\n",
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values\n",
    "\n",
    "X_tr = torch.from_numpy(X_train).float()\n",
    "y_trA = torch.from_numpy(y_train[:,[0]]).float()\n",
    "y_trB = torch.from_numpy(y_train[:,[1]]).float()\n",
    "X_te = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = NBNLLLoss(eps=1e-4)\n",
    "neural = NBNet(len(col),30,20,4,0.3)\n",
    "optimizer = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural.train()\n",
    "    muA,alphaA,muB,alphaB = neural(X_tr)\n",
    "    lossA = crit(muA,alphaA,y_trA)\n",
    "    lossB = crit(muB,alphaB,y_trB)\n",
    "    loss = lossA+lossB\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_tr = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_train)\n",
    "    # evaluate\n",
    "    neural.eval()\n",
    "    muA,alphaA,muB,alphaB = neural(X_te)\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_val = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_test)\n",
    "    # update\n",
    "    print(epoch,loss.item(),tend_acc_tr,tend_acc_val)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural.eval()\n",
    "muA,alphaA,muB,alphaB=neural(X_te)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"teamA_def_mean\": teamA_def_mean,\n",
    "    \"teamA_def_std\": teamA_def_std,\n",
    "    \"teamA_off_mean\": teamA_off_mean,\n",
    "    \"teamA_off_std\": teamA_off_std,\n",
    "    \"teamB_def_mean\": teamB_def_mean,\n",
    "    \"teamB_def_std\": teamB_def_std,\n",
    "    \"teamB_off_mean\": teamB_off_mean,\n",
    "    \"teamB_off_std\": teamB_off_std,\n",
    "    \"teamA_frag_mean\": teamA_frag_mean, \n",
    "    \"teamA_frag_std\": teamA_frag_std,\n",
    "    \"teamB_frag_mean\": teamB_frag_mean, \n",
    "    \"teamB_frag_std\": teamB_frag_std,\n",
    "    \"teamA_age_mean\": teamA_age_mean, \n",
    "    \"teamA_age_std\": teamA_age_std,\n",
    "    \"teamB_age_mean\": teamB_age_mean,\n",
    "    \"teamB_age_std\": teamB_age_std,\n",
    "    \"state_dict\": neural.state_dict(),\n",
    "}\n",
    "#torch.save(state, 'model/model_r.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_pois = torch.nn.PoissonNLLLoss()\n",
    "neural_pois = PoNet(len(col),30,20,2,0.3)\n",
    "optimizer_pois = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural_pois.train()\n",
    "    mu = neural_pois(X_tr)\n",
    "    lossA_pois = crit_pois(mu[:,[0]],y_trA)\n",
    "    lossB_pois = crit_pois(mu[:,[1]],y_trB)\n",
    "    loss_pois = lossA_pois+lossB_pois    \n",
    "    tend_acc_tr = util.tend_acc_pois(mu.data.numpy(),y_train)\n",
    "    # evaluate\n",
    "    neural_pois.eval()\n",
    "    mu = neural_pois(X_te)\n",
    "    tend_acc_val = util.tend_acc_pois(mu.data.numpy(),y_test)\n",
    "    print(epoch, loss_pois.item(),tend_acc_tr,tend_acc_val)\n",
    "    # update\n",
    "    optimizer_pois.zero_grad()\n",
    "    loss_pois.backward()\n",
    "    optimizer_pois.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pois.eval()\n",
    "mu=neural_pois(X_te).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=util.calc_pois_probs(mu[:,0],mu[:,1])\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/docs/master/notes/serialization.html#best-practices\n",
    "#https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Spieltag\n",
    "neural_pickled = NBNet(len(col),20,20,4,0.2)\n",
    "state = torch.load('model/model_r1.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "#state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[0:16]\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "wm.describe()\n",
    "#scale\n",
    "scale(wm, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[col].values).float()\n",
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy of 56.25%\n",
    "\n",
    "Top-3 accuracy of 31.25%\n",
    "\n",
    "Top-1 accuracy of 18.75%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[[\"resultA\",\"resultB\"]].values,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Spieltag\n",
    "# Was retrained on past tournaments and Game 1 results\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.3)\n",
    "state = torch.load('model/model_r2.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "#state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process World Cup Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[16:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scale(wm,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[col].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy of 50%\n",
    "\n",
    "Top-3 accuracy of 37.5%\n",
    "\n",
    "Top-1 accuracy of 12.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[[\"resultA\",\"resultB\"]].values,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm_tr.requires_grad_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#end = muA.mean()\n",
    "#end.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Spieltag\n",
    "# Was retrained on past tournaments and Game 1,2 results\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.3)\n",
    "state = torch.load('model/model_r3.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "#state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[32:48]\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "#scale\n",
    "scale(wm,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[col].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy 62.5%\n",
    "\n",
    "Top-3 accuracy 43.75%\n",
    "\n",
    "Top-1 accuracy 18.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[[\"resultA\",\"resultB\"]].values,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm_tr.requires_grad_()\n",
    "#wm_tr.grad.data.zero_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#expA = muA.mean()\n",
    "#expA.backward()\n",
    "#wm_tr.grad.mean(dim=0)\n",
    "\n",
    "#wm_tr.grad.data.zero_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#expB = muB.mean()\n",
    "#expB.backward()\n",
    "#wm_tr.grad.mean(dim=0)\n",
    "\n",
    "#wm_tr.grad.data.zero_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#disB = alphaB.mean()\n",
    "#disB.backward()\n",
    "#wm_tr.grad.mean(dim=0)\n",
    "\n",
    "#wm_tr.grad.data.zero_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#disA = alphaA.mean()\n",
    "#disA.backward()\n",
    "#wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knockout Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"gametype\",\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round of 16\n",
    "neural_pickled = NBNet(len(col),30,30,4,0.25)\n",
    "state = torch.load('model/model_ko16.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[48:56]\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "#state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scale(wm,state)\n",
    "wm[\"gametype\"]=wm[\"gametype\"].apply(map_to_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[col].values).float()\n",
    "\n",
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "#print(muA.mean(),muB.mean(),alphaA.mean(),alphaB.mean())\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "util.multi_result(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs,top_n=3,verbose=True)\n",
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)\n",
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viertelfinale\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.25)\n",
    "state = torch.load('model/model_ko8.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "\n",
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[56:60]\n",
    "#state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scale(wm,state)\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "wm[\"gametype\"]=wm[\"gametype\"].apply(map_to_round)\n",
    "# Viertelfinale\n",
    "wm_tr = torch.from_numpy(wm[col].values).float()\n",
    "\n",
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "#print(muA.mean(),muB.mean(),alphaA.mean(),alphaB.mean())\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "util.multi_result(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs,top_n=3,verbose=True)\n",
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)\n",
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Halbfinale/Finals\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.5)\n",
    "state = torch.load('model/model_ko4.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])\n",
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)[60:64]\n",
    "#state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scale(wm,state)\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "wm[\"gametype\"]=wm[\"gametype\"].apply(map_to_round)\n",
    "\n",
    "wm_tr = torch.from_numpy(wm[col].values).float()\n",
    "\n",
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "#print(muA.mean(),muB.mean(),alphaA.mean(),alphaB.mean())\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "util.multi_result(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs,top_n=5,verbose=True)\n",
    "util.single_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)\n",
    "util.multi_tendency(y=wm[[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
