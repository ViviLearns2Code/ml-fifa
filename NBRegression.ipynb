{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB Regression with PyTorch\n",
    "\n",
    "Negative binomial regression is in fact a 1-layer neural network with a special loss function. Here we increase the number of layers so that the mean $\\mu$ of the negative binomial distribution is no longer approximated by a purely linear combination of the features. At the same time, we also regress the dispersion $\\alpha$ which determines the variance ($\\mu+\\alpha\\mu²$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from NBPyTorch import NBNet, PoNet, NBNLLLoss\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from util import MyUtil\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "util=MyUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(muA,alphaA,muB,alphaB):\n",
    "    return muA.data.numpy(),alphaA.data.numpy(),muB.data.numpy(),alphaB.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tournament        object\n",
       "gametype           int64\n",
       "teamA             object\n",
       "teamB             object\n",
       "resultA            int64\n",
       "resultB            int64\n",
       "addinfo           object\n",
       "date              object\n",
       "teamA_age        float64\n",
       "teamB_age        float64\n",
       "teamA_def_val    float64\n",
       "teamB_def_val    float64\n",
       "teamA_off_val    float64\n",
       "teamB_off_val    float64\n",
       "teamA_frag         int64\n",
       "teamB_frag         int64\n",
       "past_resultA     float64\n",
       "past_resultB     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data/final.csv: past tournaments\n",
    "# data/final_w_18: updated with WC 2018 results\n",
    "data = pd.read_csv(filepath_or_buffer=\"data/final.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "\n",
    "# impute missing past values with 0\n",
    "data.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "# drop id columns\n",
    "data.drop([\"gameid\",\"teamidA\",\"teamidB\"],axis=1,inplace=True)\n",
    "\n",
    "# Encode gametype\n",
    "rounds = {\n",
    "    \"Finale\": 1,\n",
    "    \"Spiel um Platz Drei\": 2,\n",
    "    \"Halbfinale\": 3,\n",
    "    \"Viertelfinale\": 4,\n",
    "    \"Achtelfinale\": 5,\n",
    "    \"Gruppenphase\": 6\n",
    "}\n",
    "def map_to_round(x):\n",
    "    if x.startswith(\"Gruppe\"):\n",
    "        return rounds[\"Gruppenphase\"]\n",
    "    else:\n",
    "        return rounds[x]\n",
    "\n",
    "data[\"gametype\"]=data[\"gametype\"].apply(map_to_round)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knockout stage w/o pens\n",
    "data_ko=data.drop(data[data.gametype == 6].index,axis=0).copy()\n",
    "data_ko.drop(data_ko[data_ko.addinfo == 'n.E.'].index,axis=0,inplace=True) # drop pens\n",
    "\n",
    "# group stage \n",
    "data_gr=data.drop(data[data.gametype != 6].index,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knockout stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tournament</th>\n",
       "      <th>gametype</th>\n",
       "      <th>teamA</th>\n",
       "      <th>teamB</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>addinfo</th>\n",
       "      <th>date</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>AC13</td>\n",
       "      <td>4</td>\n",
       "      <td>Elfenbeinküste</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03.02.13</td>\n",
       "      <td>27.83</td>\n",
       "      <td>23.95</td>\n",
       "      <td>3219230.77</td>\n",
       "      <td>2830769.23</td>\n",
       "      <td>9765000.00</td>\n",
       "      <td>5483333.33</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>AC13</td>\n",
       "      <td>4</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>Togo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>n.V.</td>\n",
       "      <td>03.02.13</td>\n",
       "      <td>26.41</td>\n",
       "      <td>25.17</td>\n",
       "      <td>919230.77</td>\n",
       "      <td>620833.33</td>\n",
       "      <td>1294444.44</td>\n",
       "      <td>1577272.73</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>AC13</td>\n",
       "      <td>4</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Kap Verde</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02.02.13</td>\n",
       "      <td>24.39</td>\n",
       "      <td>25.48</td>\n",
       "      <td>1313333.33</td>\n",
       "      <td>359615.38</td>\n",
       "      <td>4781250.00</td>\n",
       "      <td>1020000.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>GC11</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.06.11</td>\n",
       "      <td>26.83</td>\n",
       "      <td>26.17</td>\n",
       "      <td>2622727.27</td>\n",
       "      <td>2833333.33</td>\n",
       "      <td>2925000.00</td>\n",
       "      <td>4541666.67</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>GC11</td>\n",
       "      <td>3</td>\n",
       "      <td>USA</td>\n",
       "      <td>Panama</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.06.11</td>\n",
       "      <td>27.00</td>\n",
       "      <td>24.56</td>\n",
       "      <td>2850000.00</td>\n",
       "      <td>477272.73</td>\n",
       "      <td>2246428.57</td>\n",
       "      <td>182142.86</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>GC11</td>\n",
       "      <td>3</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>n.V.</td>\n",
       "      <td>23.06.11</td>\n",
       "      <td>26.56</td>\n",
       "      <td>26.17</td>\n",
       "      <td>1958333.33</td>\n",
       "      <td>2833333.33</td>\n",
       "      <td>750000.00</td>\n",
       "      <td>4541666.67</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>GC11</td>\n",
       "      <td>4</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.06.11</td>\n",
       "      <td>26.21</td>\n",
       "      <td>25.15</td>\n",
       "      <td>3187500.00</td>\n",
       "      <td>171428.57</td>\n",
       "      <td>4541666.67</td>\n",
       "      <td>266666.67</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>GC11</td>\n",
       "      <td>4</td>\n",
       "      <td>Jamaika</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.06.11</td>\n",
       "      <td>26.93</td>\n",
       "      <td>26.36</td>\n",
       "      <td>415625.00</td>\n",
       "      <td>3550000.00</td>\n",
       "      <td>495833.33</td>\n",
       "      <td>3153571.43</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tournament  gametype           teamA      teamB  resultA  resultB addinfo  \\\n",
       "513       AC13         4  Elfenbeinküste    Nigeria        1        2     NaN   \n",
       "514       AC13         4    Burkina Faso       Togo        1        0    n.V.   \n",
       "515       AC13         4           Ghana  Kap Verde        2        0     NaN   \n",
       "541       GC11         1             USA     Mexiko        2        4     NaN   \n",
       "542       GC11         3             USA     Panama        1        0     NaN   \n",
       "543       GC11         3        Honduras     Mexiko        0        2    n.V.   \n",
       "545       GC11         4          Mexiko  Guatemala        2        1     NaN   \n",
       "546       GC11         4         Jamaika        USA        0        2     NaN   \n",
       "\n",
       "         date  teamA_age  teamB_age  teamA_def_val  teamB_def_val  \\\n",
       "513  03.02.13      27.83      23.95     3219230.77     2830769.23   \n",
       "514  03.02.13      26.41      25.17      919230.77      620833.33   \n",
       "515  02.02.13      24.39      25.48     1313333.33      359615.38   \n",
       "541  26.06.11      26.83      26.17     2622727.27     2833333.33   \n",
       "542  23.06.11      27.00      24.56     2850000.00      477272.73   \n",
       "543  23.06.11      26.56      26.17     1958333.33     2833333.33   \n",
       "545  19.06.11      26.21      25.15     3187500.00      171428.57   \n",
       "546  19.06.11      26.93      26.36      415625.00     3550000.00   \n",
       "\n",
       "     teamA_off_val  teamB_off_val  teamA_frag  teamB_frag  past_resultA  \\\n",
       "513     9765000.00     5483333.33          19          19          1.00   \n",
       "514     1294444.44     1577272.73          19          18          0.95   \n",
       "515     4781250.00     1020000.00          20          20          3.90   \n",
       "541     2925000.00     4541666.67          16          16          0.95   \n",
       "542     2246428.57      182142.86          16          16          1.05   \n",
       "543      750000.00     4541666.67          11          16          0.15   \n",
       "545     4541666.67      266666.67          13           9          0.11   \n",
       "546      495833.33     3153571.43          11          13          1.00   \n",
       "\n",
       "     past_resultB  \n",
       "513          0.00  \n",
       "514          0.95  \n",
       "515          0.00  \n",
       "541          2.14  \n",
       "542          1.95  \n",
       "543          1.00  \n",
       "545          0.15  \n",
       "546          1.10  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ko.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_ko.copy(),test_size=0.2)\n",
    "col=[\"gametype\",\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamA_def_mean = data_train[\"teamA_def_val\"].mean()\n",
    "teamA_def_std = data_train[\"teamA_def_val\"].std()\n",
    "teamA_off_mean = data_train[\"teamA_off_val\"].mean()\n",
    "teamA_off_std = data_train[\"teamA_off_val\"].std()\n",
    "\n",
    "teamB_def_mean = data_train[\"teamB_def_val\"].mean()\n",
    "teamB_def_std = data_train[\"teamB_def_val\"].std()\n",
    "teamB_off_mean = data_train[\"teamB_off_val\"].mean()\n",
    "teamB_off_std = data_train[\"teamB_off_val\"].std()\n",
    "\n",
    "teamA_frag_mean = data_train[\"teamA_frag\"].mean()\n",
    "teamA_frag_std = data_train[\"teamA_frag\"].std()\n",
    "\n",
    "teamB_frag_mean = data_train[\"teamB_frag\"].mean()\n",
    "teamB_frag_std = data_train[\"teamB_frag\"].std()\n",
    "\n",
    "teamA_age_mean = data_train[\"teamA_age\"].mean()\n",
    "teamA_age_std = data_train[\"teamA_age\"].std()\n",
    "\n",
    "teamB_age_mean = data_train[\"teamB_age\"].mean()\n",
    "teamB_age_std = data_train[\"teamB_age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train features\n",
    "data_train[\"teamA_def_val\"]=(data_train[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_train[\"teamA_off_val\"]=(data_train[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_train[\"teamB_def_val\"]=(data_train[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_train[\"teamB_off_val\"]=(data_train[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_train[\"teamA_frag\"]=(data_train[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_train[\"teamB_frag\"]=(data_train[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_train[\"teamA_age\"]=(data_train[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_train[\"teamB_age\"]=(data_train[\"teamB_age\"]-teamB_age_mean)/teamB_age_std\n",
    "\n",
    "# scale test features\n",
    "data_test[\"teamA_def_val\"]=(data_test[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_test[\"teamA_off_val\"]=(data_test[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_test[\"teamB_def_val\"]=(data_test[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_test[\"teamB_off_val\"]=(data_test[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_test[\"teamA_frag\"]=(data_test[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_test[\"teamB_frag\"]=(data_test[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_test[\"teamA_age\"]=(data_test[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_test[\"teamB_age\"]=(data_test[\"teamB_age\"]-teamB_age_mean)/teamB_age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gametype</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.460674</td>\n",
       "      <td>1.573034</td>\n",
       "      <td>1.191011</td>\n",
       "      <td>-1.947256e-15</td>\n",
       "      <td>-3.253328e-15</td>\n",
       "      <td>7.235161e-17</td>\n",
       "      <td>-2.245395e-17</td>\n",
       "      <td>8.732091e-17</td>\n",
       "      <td>-6.985673e-17</td>\n",
       "      <td>2.295293e-16</td>\n",
       "      <td>-1.521879e-16</td>\n",
       "      <td>1.160337</td>\n",
       "      <td>1.112472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.340422</td>\n",
       "      <td>1.287065</td>\n",
       "      <td>1.251149</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.307872</td>\n",
       "      <td>1.074248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.150748e+00</td>\n",
       "      <td>-2.124791e+00</td>\n",
       "      <td>-1.021065e+00</td>\n",
       "      <td>-8.597411e-01</td>\n",
       "      <td>-1.132683e+00</td>\n",
       "      <td>-9.157056e-01</td>\n",
       "      <td>-1.956158e+00</td>\n",
       "      <td>-2.202777e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.908092e-01</td>\n",
       "      <td>-5.865828e-01</td>\n",
       "      <td>-8.045210e-01</td>\n",
       "      <td>-6.680256e-01</td>\n",
       "      <td>-8.807878e-01</td>\n",
       "      <td>-7.045045e-01</td>\n",
       "      <td>-6.760253e-01</td>\n",
       "      <td>-7.239732e-01</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.072312e-01</td>\n",
       "      <td>-1.169674e-02</td>\n",
       "      <td>-3.956967e-01</td>\n",
       "      <td>-4.297661e-01</td>\n",
       "      <td>-2.048655e-01</td>\n",
       "      <td>-4.562801e-01</td>\n",
       "      <td>9.205451e-02</td>\n",
       "      <td>1.210578e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.325000e-01</td>\n",
       "      <td>7.185639e-01</td>\n",
       "      <td>5.070001e-01</td>\n",
       "      <td>3.297609e-01</td>\n",
       "      <td>6.513724e-01</td>\n",
       "      <td>5.383002e-01</td>\n",
       "      <td>6.041077e-01</td>\n",
       "      <td>7.548310e-01</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.843175e+00</td>\n",
       "      <td>1.860567e+00</td>\n",
       "      <td>2.742703e+00</td>\n",
       "      <td>3.288464e+00</td>\n",
       "      <td>2.600330e+00</td>\n",
       "      <td>2.984362e+00</td>\n",
       "      <td>1.884241e+00</td>\n",
       "      <td>1.599862e+00</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gametype    resultA    resultB     teamA_age     teamB_age  \\\n",
       "count  89.000000  89.000000  89.000000  8.900000e+01  8.900000e+01   \n",
       "mean    3.460674   1.573034   1.191011 -1.947256e-15 -3.253328e-15   \n",
       "std     1.340422   1.287065   1.251149  1.000000e+00  1.000000e+00   \n",
       "min     1.000000   0.000000   0.000000 -3.150748e+00 -2.124791e+00   \n",
       "25%     3.000000   1.000000   0.000000 -6.908092e-01 -5.865828e-01   \n",
       "50%     4.000000   1.000000   1.000000  1.072312e-01 -1.169674e-02   \n",
       "75%     5.000000   2.000000   2.000000  7.325000e-01  7.185639e-01   \n",
       "max     5.000000   6.000000   6.000000  1.843175e+00  1.860567e+00   \n",
       "\n",
       "       teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  \\\n",
       "count   8.900000e+01   8.900000e+01   8.900000e+01   8.900000e+01   \n",
       "mean    7.235161e-17  -2.245395e-17   8.732091e-17  -6.985673e-17   \n",
       "std     1.000000e+00   1.000000e+00   1.000000e+00   1.000000e+00   \n",
       "min    -1.021065e+00  -8.597411e-01  -1.132683e+00  -9.157056e-01   \n",
       "25%    -8.045210e-01  -6.680256e-01  -8.807878e-01  -7.045045e-01   \n",
       "50%    -3.956967e-01  -4.297661e-01  -2.048655e-01  -4.562801e-01   \n",
       "75%     5.070001e-01   3.297609e-01   6.513724e-01   5.383002e-01   \n",
       "max     2.742703e+00   3.288464e+00   2.600330e+00   2.984362e+00   \n",
       "\n",
       "         teamA_frag    teamB_frag  past_resultA  past_resultB  \n",
       "count  8.900000e+01  8.900000e+01     89.000000     89.000000  \n",
       "mean   2.295293e-16 -1.521879e-16      1.160337      1.112472  \n",
       "std    1.000000e+00  1.000000e+00      1.307872      1.074248  \n",
       "min   -1.956158e+00 -2.202777e+00      0.000000      0.000000  \n",
       "25%   -6.760253e-01 -7.239732e-01      0.050000      0.050000  \n",
       "50%    9.205451e-02  1.210578e-01      1.000000      1.000000  \n",
       "75%    6.041077e-01  7.548310e-01      1.900000      1.900000  \n",
       "max    1.884241e+00  1.599862e+00      6.700000      5.750000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = torch.from_numpy(X_train).float()\n",
    "y_trA = torch.from_numpy(y_train[:,[0]]).float()\n",
    "y_trB = torch.from_numpy(y_train[:,[1]]).float()\n",
    "X_te = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = NBNLLLoss(eps=1e-3,verbose=False)\n",
    "def fn_print(module, grad_input, grad_output):\n",
    "    print(\"Gradients Input\",grad_input)\n",
    "    print(\"Gradients Output\", grad_output)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = NBNet(len(col),30,20,4,0.5)\n",
    "optimizer = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2290244102478027 0.5168539325842697 0.6086956521739131\n",
      "1 3.2297208309173584 0.550561797752809 0.6086956521739131\n",
      "2 3.1443190574645996 0.5842696629213483 0.6521739130434783\n",
      "3 3.143949031829834 0.5842696629213483 0.6086956521739131\n",
      "4 3.1881117820739746 0.5955056179775281 0.6521739130434783\n",
      "5 3.154956817626953 0.5955056179775281 0.6086956521739131\n",
      "6 3.2091565132141113 0.5393258426966292 0.6086956521739131\n",
      "7 3.1498215198516846 0.6067415730337079 0.6521739130434783\n",
      "8 3.1710119247436523 0.5056179775280899 0.6521739130434783\n",
      "9 3.1463379859924316 0.6292134831460674 0.6521739130434783\n",
      "10 3.128599166870117 0.6067415730337079 0.6521739130434783\n",
      "11 3.1305060386657715 0.6853932584269663 0.6521739130434783\n",
      "12 3.0908002853393555 0.6179775280898876 0.6086956521739131\n",
      "13 3.110560894012451 0.651685393258427 0.6086956521739131\n",
      "14 3.1394729614257812 0.550561797752809 0.6521739130434783\n",
      "15 3.100520610809326 0.6404494382022472 0.6086956521739131\n",
      "16 3.0905399322509766 0.6067415730337079 0.6956521739130435\n",
      "17 3.1148128509521484 0.6404494382022472 0.6521739130434783\n",
      "18 3.1038479804992676 0.5955056179775281 0.6521739130434783\n",
      "19 2.9874134063720703 0.5842696629213483 0.6956521739130435\n",
      "20 3.033169746398926 0.6966292134831461 0.6086956521739131\n",
      "21 3.062256336212158 0.6292134831460674 0.6086956521739131\n",
      "22 3.1183853149414062 0.5842696629213483 0.6521739130434783\n",
      "23 3.094294786453247 0.651685393258427 0.6521739130434783\n",
      "24 3.0909194946289062 0.5955056179775281 0.6521739130434783\n",
      "25 3.072652816772461 0.6853932584269663 0.6521739130434783\n",
      "26 3.072415590286255 0.6853932584269663 0.6086956521739131\n",
      "27 3.0832059383392334 0.6179775280898876 0.6086956521739131\n",
      "28 3.1351068019866943 0.6741573033707865 0.6521739130434783\n",
      "29 3.0565671920776367 0.6741573033707865 0.6086956521739131\n",
      "30 3.063027858734131 0.5955056179775281 0.6086956521739131\n",
      "31 3.1031723022460938 0.6067415730337079 0.6521739130434783\n",
      "32 3.0544376373291016 0.7078651685393258 0.6086956521739131\n",
      "33 3.1007704734802246 0.651685393258427 0.6521739130434783\n",
      "34 3.052692413330078 0.6179775280898876 0.6086956521739131\n",
      "35 3.024249792098999 0.7303370786516854 0.6086956521739131\n",
      "36 3.028568744659424 0.6404494382022472 0.5652173913043478\n",
      "37 3.0083255767822266 0.6179775280898876 0.6086956521739131\n",
      "38 3.004338026046753 0.6853932584269663 0.6086956521739131\n",
      "39 3.0439393520355225 0.7078651685393258 0.6086956521739131\n",
      "40 3.0639681816101074 0.6853932584269663 0.5652173913043478\n",
      "41 3.0508861541748047 0.6067415730337079 0.5652173913043478\n",
      "42 3.009652614593506 0.6629213483146067 0.5652173913043478\n",
      "43 3.037604570388794 0.7078651685393258 0.5652173913043478\n",
      "44 3.0098536014556885 0.6741573033707865 0.5652173913043478\n",
      "45 3.0083835124969482 0.7191011235955056 0.6086956521739131\n",
      "46 2.991368293762207 0.6179775280898876 0.5652173913043478\n",
      "47 3.0255188941955566 0.6853932584269663 0.6086956521739131\n",
      "48 3.0517678260803223 0.6404494382022472 0.6521739130434783\n",
      "49 2.993685007095337 0.7303370786516854 0.6086956521739131\n",
      "50 3.0211925506591797 0.6629213483146067 0.6086956521739131\n",
      "51 3.073225498199463 0.6067415730337079 0.6086956521739131\n",
      "52 3.098292827606201 0.7191011235955056 0.6086956521739131\n",
      "53 3.035849094390869 0.6067415730337079 0.5652173913043478\n",
      "54 2.9895291328430176 0.6741573033707865 0.5652173913043478\n",
      "55 3.035752296447754 0.6292134831460674 0.6086956521739131\n",
      "56 3.0211682319641113 0.7191011235955056 0.6521739130434783\n",
      "57 3.0124874114990234 0.7078651685393258 0.6086956521739131\n",
      "58 2.9925808906555176 0.6629213483146067 0.6521739130434783\n",
      "59 3.024564266204834 0.6404494382022472 0.6521739130434783\n",
      "60 3.0132944583892822 0.7415730337078652 0.6086956521739131\n",
      "61 3.014921188354492 0.6179775280898876 0.5652173913043478\n",
      "62 2.983685255050659 0.7640449438202247 0.6086956521739131\n",
      "63 3.040876865386963 0.6629213483146067 0.5652173913043478\n",
      "64 3.031146764755249 0.6292134831460674 0.6086956521739131\n",
      "65 3.0034849643707275 0.6629213483146067 0.6956521739130435\n",
      "66 2.977327823638916 0.5617977528089888 0.6521739130434783\n",
      "67 3.012394905090332 0.7078651685393258 0.6086956521739131\n",
      "68 2.9198954105377197 0.7303370786516854 0.5652173913043478\n",
      "69 2.9650583267211914 0.7752808988764045 0.6086956521739131\n",
      "70 2.987252712249756 0.6966292134831461 0.6086956521739131\n",
      "71 2.9918437004089355 0.6292134831460674 0.6086956521739131\n",
      "72 2.962007522583008 0.6741573033707865 0.6086956521739131\n",
      "73 3.0660948753356934 0.5955056179775281 0.6521739130434783\n",
      "74 2.9492201805114746 0.6853932584269663 0.6521739130434783\n",
      "75 2.9417724609375 0.7078651685393258 0.6521739130434783\n",
      "76 2.969693183898926 0.7415730337078652 0.6521739130434783\n",
      "77 3.035727024078369 0.6741573033707865 0.6521739130434783\n",
      "78 3.0055813789367676 0.6179775280898876 0.6521739130434783\n",
      "79 2.9809257984161377 0.6629213483146067 0.6521739130434783\n",
      "80 2.9710817337036133 0.6292134831460674 0.6521739130434783\n",
      "81 2.938030242919922 0.7191011235955056 0.6521739130434783\n",
      "82 3.0039896965026855 0.6853932584269663 0.6521739130434783\n",
      "83 3.0164265632629395 0.651685393258427 0.6521739130434783\n",
      "84 3.009704113006592 0.7640449438202247 0.6956521739130435\n",
      "85 3.014078140258789 0.6179775280898876 0.6521739130434783\n",
      "86 2.988260507583618 0.7078651685393258 0.6521739130434783\n",
      "87 2.980700969696045 0.6741573033707865 0.6521739130434783\n",
      "88 2.9619932174682617 0.7078651685393258 0.6521739130434783\n",
      "89 3.017643451690674 0.6292134831460674 0.6521739130434783\n",
      "90 2.9535508155822754 0.7528089887640449 0.6956521739130435\n",
      "91 2.9164810180664062 0.7415730337078652 0.6521739130434783\n",
      "92 2.9844460487365723 0.6966292134831461 0.6521739130434783\n",
      "93 2.9652485847473145 0.6966292134831461 0.6521739130434783\n",
      "94 2.965787410736084 0.6853932584269663 0.6521739130434783\n",
      "95 2.9464874267578125 0.7303370786516854 0.6521739130434783\n",
      "96 2.9630253314971924 0.7303370786516854 0.6521739130434783\n",
      "97 2.920063018798828 0.7191011235955056 0.6521739130434783\n",
      "98 2.9738268852233887 0.6966292134831461 0.6521739130434783\n",
      "99 2.9449691772460938 0.6853932584269663 0.6521739130434783\n",
      "100 2.9858455657958984 0.7078651685393258 0.6956521739130435\n",
      "101 3.0244927406311035 0.6629213483146067 0.6956521739130435\n",
      "102 3.065291404724121 0.6853932584269663 0.6956521739130435\n",
      "103 3.009627103805542 0.6404494382022472 0.6956521739130435\n",
      "104 2.9242095947265625 0.7528089887640449 0.6956521739130435\n",
      "105 2.896427869796753 0.7640449438202247 0.6956521739130435\n",
      "106 2.915705442428589 0.6966292134831461 0.6521739130434783\n",
      "107 3.012967109680176 0.6292134831460674 0.6521739130434783\n",
      "108 2.9883387088775635 0.6629213483146067 0.6086956521739131\n",
      "109 3.006464719772339 0.6629213483146067 0.6521739130434783\n",
      "110 2.9518580436706543 0.6629213483146067 0.6521739130434783\n",
      "111 2.9754867553710938 0.7078651685393258 0.6521739130434783\n",
      "112 2.9506149291992188 0.7078651685393258 0.6521739130434783\n",
      "113 2.915095329284668 0.6966292134831461 0.6521739130434783\n",
      "114 2.920926094055176 0.7415730337078652 0.6521739130434783\n",
      "115 2.9888668060302734 0.7078651685393258 0.6521739130434783\n",
      "116 2.9969258308410645 0.6853932584269663 0.6521739130434783\n",
      "117 2.953098773956299 0.6853932584269663 0.6521739130434783\n",
      "118 2.920891284942627 0.7752808988764045 0.6521739130434783\n",
      "119 2.989715814590454 0.6853932584269663 0.6521739130434783\n",
      "120 2.9108948707580566 0.6853932584269663 0.6521739130434783\n",
      "121 2.9542429447174072 0.7191011235955056 0.6521739130434783\n",
      "122 2.922848701477051 0.6853932584269663 0.6521739130434783\n",
      "123 2.9510419368743896 0.7303370786516854 0.6521739130434783\n",
      "124 2.8840932846069336 0.7303370786516854 0.6521739130434783\n",
      "125 2.9196457862854004 0.7303370786516854 0.6521739130434783\n",
      "126 2.944945812225342 0.6404494382022472 0.6521739130434783\n",
      "127 2.927218198776245 0.7303370786516854 0.6521739130434783\n",
      "128 2.967284679412842 0.6853932584269663 0.6956521739130435\n",
      "129 2.9959049224853516 0.7528089887640449 0.6521739130434783\n",
      "130 2.969118595123291 0.6629213483146067 0.6956521739130435\n",
      "131 2.8946986198425293 0.7415730337078652 0.6521739130434783\n",
      "132 2.9376964569091797 0.7078651685393258 0.6521739130434783\n",
      "133 2.978043556213379 0.6741573033707865 0.6956521739130435\n",
      "134 2.913774013519287 0.6853932584269663 0.6521739130434783\n",
      "135 2.9236977100372314 0.7191011235955056 0.6086956521739131\n",
      "136 3.0185799598693848 0.6179775280898876 0.6956521739130435\n",
      "137 2.9723095893859863 0.6966292134831461 0.6521739130434783\n",
      "138 2.9720070362091064 0.6853932584269663 0.6521739130434783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 2.9176738262176514 0.6853932584269663 0.6521739130434783\n",
      "140 2.8875811100006104 0.7752808988764045 0.6521739130434783\n",
      "141 2.9195761680603027 0.7078651685393258 0.6521739130434783\n",
      "142 2.9549942016601562 0.6853932584269663 0.6521739130434783\n",
      "143 2.9578917026519775 0.6179775280898876 0.6521739130434783\n",
      "144 2.9062752723693848 0.6292134831460674 0.6521739130434783\n",
      "145 2.9013543128967285 0.7303370786516854 0.6956521739130435\n",
      "146 2.8675968647003174 0.6629213483146067 0.6956521739130435\n",
      "147 2.9194488525390625 0.7415730337078652 0.6956521739130435\n",
      "148 2.945643424987793 0.6966292134831461 0.6956521739130435\n",
      "149 2.858874797821045 0.7640449438202247 0.6956521739130435\n",
      "150 2.8615283966064453 0.7078651685393258 0.6521739130434783\n",
      "151 2.9395923614501953 0.6966292134831461 0.6956521739130435\n",
      "152 2.868809700012207 0.7640449438202247 0.6521739130434783\n",
      "153 2.9435105323791504 0.7752808988764045 0.6521739130434783\n",
      "154 2.958925247192383 0.7303370786516854 0.6521739130434783\n",
      "155 2.893820285797119 0.6853932584269663 0.6521739130434783\n",
      "156 2.8962907791137695 0.7078651685393258 0.6521739130434783\n",
      "157 2.874052047729492 0.6966292134831461 0.6521739130434783\n",
      "158 2.8532629013061523 0.7640449438202247 0.6521739130434783\n",
      "159 2.8489646911621094 0.7528089887640449 0.6521739130434783\n",
      "160 2.9043004512786865 0.6853932584269663 0.6956521739130435\n",
      "161 2.843257427215576 0.7078651685393258 0.6956521739130435\n",
      "162 2.911044120788574 0.6853932584269663 0.6956521739130435\n",
      "163 2.932425022125244 0.6966292134831461 0.6956521739130435\n",
      "164 2.9160828590393066 0.7415730337078652 0.6956521739130435\n",
      "165 2.819681167602539 0.7752808988764045 0.6956521739130435\n",
      "166 2.867335796356201 0.7528089887640449 0.6956521739130435\n",
      "167 2.78322434425354 0.7528089887640449 0.6956521739130435\n",
      "168 2.9023020267486572 0.7303370786516854 0.6956521739130435\n",
      "169 2.9681777954101562 0.6629213483146067 0.6956521739130435\n",
      "170 2.8949317932128906 0.7415730337078652 0.6956521739130435\n",
      "171 2.9534692764282227 0.6741573033707865 0.6521739130434783\n",
      "172 2.9331607818603516 0.6404494382022472 0.6956521739130435\n",
      "173 2.9325413703918457 0.7415730337078652 0.6956521739130435\n",
      "174 2.938229560852051 0.6741573033707865 0.6956521739130435\n",
      "175 2.87205171585083 0.7191011235955056 0.6956521739130435\n",
      "176 2.832162857055664 0.7528089887640449 0.6956521739130435\n",
      "177 2.884331703186035 0.7191011235955056 0.6521739130434783\n",
      "178 2.8654534816741943 0.8089887640449438 0.6521739130434783\n",
      "179 2.908761978149414 0.6853932584269663 0.6521739130434783\n",
      "180 2.8856871128082275 0.7528089887640449 0.6521739130434783\n",
      "181 2.8736467361450195 0.7303370786516854 0.6956521739130435\n",
      "182 2.9022979736328125 0.6741573033707865 0.6956521739130435\n",
      "183 2.7956457138061523 0.8202247191011236 0.6956521739130435\n",
      "184 2.853003978729248 0.7752808988764045 0.6956521739130435\n",
      "185 2.9385006427764893 0.6966292134831461 0.6956521739130435\n",
      "186 2.9134228229522705 0.8089887640449438 0.6956521739130435\n",
      "187 2.8098578453063965 0.8426966292134831 0.6521739130434783\n",
      "188 2.930368423461914 0.7078651685393258 0.6956521739130435\n",
      "189 2.904118537902832 0.6629213483146067 0.6956521739130435\n",
      "190 2.835951328277588 0.7078651685393258 0.6956521739130435\n",
      "191 2.941117763519287 0.6404494382022472 0.6956521739130435\n",
      "192 2.8322575092315674 0.7528089887640449 0.6956521739130435\n",
      "193 2.8754801750183105 0.6741573033707865 0.6956521739130435\n",
      "194 2.875303268432617 0.6853932584269663 0.6956521739130435\n",
      "195 2.861140251159668 0.7191011235955056 0.6956521739130435\n",
      "196 2.847073554992676 0.7078651685393258 0.6956521739130435\n",
      "197 2.972095489501953 0.6966292134831461 0.6956521739130435\n",
      "198 2.9051225185394287 0.6966292134831461 0.6956521739130435\n",
      "199 2.890200138092041 0.6966292134831461 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural.train()\n",
    "    muA,alphaA,muB,alphaB = neural(X_tr)\n",
    "    lossA = crit(muA,alphaA,y_trA)\n",
    "    lossB = crit(muB,alphaB,y_trB)\n",
    "    loss = lossA+lossB\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_tr = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_train)\n",
    "    # update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # evaluate\n",
    "    neural.eval()\n",
    "    muA,alphaA,muB,alphaB = neural(X_te)\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_val = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_test)\n",
    "    print(epoch,loss.item(),tend_acc_tr,tend_acc_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural.eval()\n",
    "muA,alphaA,muB,alphaB=neural(X_te)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.08803572]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.         0.         0.13940216]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.11786911]]\n",
      "wrong prediction for [1 3]\n",
      "candidates \n",
      " [[1.         0.         0.15063886]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         1.         0.10503696]]\n",
      "wrong prediction for [1 7]\n",
      "candidates \n",
      " [[0.         0.         0.22547954]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[2.         0.         0.09954004]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.12076676]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.12936794]]\n",
      "wrong prediction for [2 4]\n",
      "candidates \n",
      " [[1.         1.         0.10184319]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.10150991]]\n",
      "wrong prediction for [2 3]\n",
      "candidates \n",
      " [[1.         1.         0.08951705]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.11309314]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.        1.        0.0950115]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         0.         0.10651543]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.09490548]]\n",
      "wrong prediction for [1 3]\n",
      "candidates \n",
      " [[1.        0.        0.1235917]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.09815527]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.        0.        0.1706486]]\n",
      "wrong prediction for [2 3]\n",
      "candidates \n",
      " [[0.         1.         0.09956984]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[1.         0.         0.11768337]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.13309788]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.10697377]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08695652173913043"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we can see that the predictions are much more diverse (4 or 5 goals can be predicted). It no longer looks as if the model memorized the most frequent game outcomes. Instead it looks like the goal counts in top-5 predictions really depend on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"teamA_def_mean\": teamA_def_mean,\n",
    "    \"teamA_def_std\": teamA_def_std,\n",
    "    \"teamA_off_mean\": teamA_off_mean,\n",
    "    \"teamA_off_std\": teamA_off_std,\n",
    "    \"teamB_def_mean\": teamB_def_mean,\n",
    "    \"teamB_def_std\": teamB_def_std,\n",
    "    \"teamB_off_mean\": teamB_off_mean,\n",
    "    \"teamB_off_std\": teamB_off_std,\n",
    "    \"teamA_frag_mean\": teamA_frag_mean, \n",
    "    \"teamA_frag_std\": teamA_frag_std,\n",
    "    \"teamB_frag_mean\": teamB_frag_mean, \n",
    "    \"teamB_frag_std\": teamB_frag_std,\n",
    "    \"teamA_age_mean\": teamA_age_mean, \n",
    "    \"teamA_age_std\": teamA_age_std,\n",
    "    \"teamB_age_mean\": teamB_age_mean,\n",
    "    \"teamB_age_std\": teamB_age_std,\n",
    "    \"state_dict\": neural.state_dict(),\n",
    "}\n",
    "#torch.save(state, 'model/model_ko8.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_pois = torch.nn.PoissonNLLLoss()\n",
    "neural_pois = PoNet(len(col),30,20,2,0.2)\n",
    "optimizer_pois = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.513723373413086 0.5056179775280899 0.391304347826087\n",
      "1 4.472173690795898 0.5056179775280899 0.391304347826087\n",
      "2 4.36558723449707 0.4157303370786517 0.391304347826087\n",
      "3 4.43808650970459 0.43820224719101125 0.391304347826087\n",
      "4 4.496966361999512 0.5056179775280899 0.391304347826087\n",
      "5 4.431865215301514 0.43820224719101125 0.391304347826087\n",
      "6 4.399778842926025 0.4943820224719101 0.391304347826087\n",
      "7 4.539257526397705 0.42696629213483145 0.391304347826087\n",
      "8 4.487360000610352 0.47191011235955055 0.391304347826087\n",
      "9 4.424665927886963 0.42696629213483145 0.391304347826087\n",
      "10 4.37591028213501 0.449438202247191 0.391304347826087\n",
      "11 4.60662841796875 0.550561797752809 0.391304347826087\n",
      "12 4.624963283538818 0.4943820224719101 0.391304347826087\n",
      "13 4.293585777282715 0.5393258426966292 0.391304347826087\n",
      "14 4.494107723236084 0.42696629213483145 0.391304347826087\n",
      "15 4.433464527130127 0.5280898876404494 0.391304347826087\n",
      "16 4.360749244689941 0.47191011235955055 0.391304347826087\n",
      "17 4.468668460845947 0.34831460674157305 0.391304347826087\n",
      "18 4.416306495666504 0.4606741573033708 0.391304347826087\n",
      "19 4.443217754364014 0.4943820224719101 0.391304347826087\n",
      "20 4.66070556640625 0.5280898876404494 0.391304347826087\n",
      "21 4.542722225189209 0.5056179775280899 0.391304347826087\n",
      "22 4.389106750488281 0.5393258426966292 0.391304347826087\n",
      "23 4.301705360412598 0.4606741573033708 0.391304347826087\n",
      "24 4.460755825042725 0.42696629213483145 0.391304347826087\n",
      "25 4.392942905426025 0.5168539325842697 0.391304347826087\n",
      "26 4.531434535980225 0.5168539325842697 0.391304347826087\n",
      "27 4.596822261810303 0.4943820224719101 0.391304347826087\n",
      "28 4.255929946899414 0.4943820224719101 0.391304347826087\n",
      "29 4.367960453033447 0.48314606741573035 0.391304347826087\n",
      "30 4.6823410987854 0.4606741573033708 0.391304347826087\n",
      "31 4.4596147537231445 0.4606741573033708 0.391304347826087\n",
      "32 4.54874324798584 0.47191011235955055 0.391304347826087\n",
      "33 4.556577682495117 0.47191011235955055 0.391304347826087\n",
      "34 4.51499080657959 0.4943820224719101 0.391304347826087\n",
      "35 4.573761463165283 0.4943820224719101 0.391304347826087\n",
      "36 4.3238396644592285 0.5056179775280899 0.391304347826087\n",
      "37 4.424402236938477 0.5168539325842697 0.391304347826087\n",
      "38 4.414844036102295 0.5056179775280899 0.391304347826087\n",
      "39 4.597849369049072 0.5393258426966292 0.391304347826087\n",
      "40 4.553950786590576 0.39325842696629215 0.391304347826087\n",
      "41 4.179638862609863 0.42696629213483145 0.391304347826087\n",
      "42 4.324277400970459 0.47191011235955055 0.391304347826087\n",
      "43 4.493042469024658 0.43820224719101125 0.391304347826087\n",
      "44 4.520507335662842 0.47191011235955055 0.391304347826087\n",
      "45 4.3393659591674805 0.39325842696629215 0.391304347826087\n",
      "46 4.461903095245361 0.47191011235955055 0.391304347826087\n",
      "47 4.503495216369629 0.550561797752809 0.391304347826087\n",
      "48 4.362017631530762 0.4943820224719101 0.391304347826087\n",
      "49 4.488889694213867 0.449438202247191 0.391304347826087\n",
      "50 4.564127445220947 0.43820224719101125 0.391304347826087\n",
      "51 4.333879470825195 0.5730337078651685 0.391304347826087\n",
      "52 4.496434211730957 0.5393258426966292 0.391304347826087\n",
      "53 4.665284633636475 0.5056179775280899 0.391304347826087\n",
      "54 4.583980560302734 0.42696629213483145 0.391304347826087\n",
      "55 4.530330657958984 0.449438202247191 0.391304347826087\n",
      "56 4.454309940338135 0.5393258426966292 0.391304347826087\n",
      "57 4.235909938812256 0.5056179775280899 0.391304347826087\n",
      "58 4.391267776489258 0.48314606741573035 0.391304347826087\n",
      "59 4.365719795227051 0.4044943820224719 0.391304347826087\n",
      "60 4.516302585601807 0.4157303370786517 0.391304347826087\n",
      "61 4.3781023025512695 0.43820224719101125 0.391304347826087\n",
      "62 4.341058254241943 0.47191011235955055 0.391304347826087\n",
      "63 4.506540775299072 0.5393258426966292 0.391304347826087\n",
      "64 4.399102210998535 0.4943820224719101 0.391304347826087\n",
      "65 4.362113952636719 0.48314606741573035 0.391304347826087\n",
      "66 4.237593650817871 0.43820224719101125 0.391304347826087\n",
      "67 4.421347618103027 0.4943820224719101 0.391304347826087\n",
      "68 4.287718772888184 0.48314606741573035 0.391304347826087\n",
      "69 4.706034183502197 0.4044943820224719 0.391304347826087\n",
      "70 4.539533615112305 0.47191011235955055 0.391304347826087\n",
      "71 4.582733631134033 0.5280898876404494 0.391304347826087\n",
      "72 4.400508880615234 0.449438202247191 0.391304347826087\n",
      "73 4.49807071685791 0.449438202247191 0.391304347826087\n",
      "74 4.280065536499023 0.5168539325842697 0.391304347826087\n",
      "75 4.407540798187256 0.5730337078651685 0.391304347826087\n",
      "76 4.4313836097717285 0.5168539325842697 0.391304347826087\n",
      "77 4.468019485473633 0.4044943820224719 0.391304347826087\n",
      "78 4.349951267242432 0.47191011235955055 0.391304347826087\n",
      "79 4.498076438903809 0.5056179775280899 0.391304347826087\n",
      "80 4.480939865112305 0.5617977528089888 0.391304347826087\n",
      "81 4.680938720703125 0.4606741573033708 0.391304347826087\n",
      "82 4.6023359298706055 0.4606741573033708 0.391304347826087\n",
      "83 4.5202531814575195 0.4606741573033708 0.391304347826087\n",
      "84 4.364628791809082 0.42696629213483145 0.391304347826087\n",
      "85 4.365910530090332 0.4606741573033708 0.391304347826087\n",
      "86 4.41434383392334 0.449438202247191 0.391304347826087\n",
      "87 4.541107177734375 0.43820224719101125 0.391304347826087\n",
      "88 4.431502342224121 0.449438202247191 0.391304347826087\n",
      "89 4.392571449279785 0.449438202247191 0.391304347826087\n",
      "90 4.524844646453857 0.4606741573033708 0.391304347826087\n",
      "91 4.679492473602295 0.449438202247191 0.391304347826087\n",
      "92 4.463074684143066 0.43820224719101125 0.391304347826087\n",
      "93 4.386214256286621 0.6404494382022472 0.391304347826087\n",
      "94 4.526956081390381 0.4157303370786517 0.391304347826087\n",
      "95 4.429337024688721 0.48314606741573035 0.391304347826087\n",
      "96 4.399336814880371 0.4044943820224719 0.391304347826087\n",
      "97 4.5293288230896 0.5393258426966292 0.391304347826087\n",
      "98 4.559098243713379 0.4943820224719101 0.391304347826087\n",
      "99 4.314802646636963 0.550561797752809 0.391304347826087\n",
      "100 4.271719932556152 0.39325842696629215 0.391304347826087\n",
      "101 4.294206142425537 0.5056179775280899 0.391304347826087\n",
      "102 4.545557022094727 0.4943820224719101 0.391304347826087\n",
      "103 4.601327419281006 0.5168539325842697 0.391304347826087\n",
      "104 4.41411828994751 0.5168539325842697 0.391304347826087\n",
      "105 4.41959285736084 0.48314606741573035 0.391304347826087\n",
      "106 4.457012176513672 0.449438202247191 0.391304347826087\n",
      "107 4.340613842010498 0.5056179775280899 0.391304347826087\n",
      "108 4.443486213684082 0.4157303370786517 0.391304347826087\n",
      "109 4.284269332885742 0.4943820224719101 0.391304347826087\n",
      "110 4.446385860443115 0.42696629213483145 0.391304347826087\n",
      "111 4.501657962799072 0.5393258426966292 0.391304347826087\n",
      "112 4.4820146560668945 0.42696629213483145 0.391304347826087\n",
      "113 4.504602909088135 0.5280898876404494 0.391304347826087\n",
      "114 4.527374267578125 0.5056179775280899 0.391304347826087\n",
      "115 4.514422416687012 0.48314606741573035 0.391304347826087\n",
      "116 4.312454700469971 0.449438202247191 0.391304347826087\n",
      "117 4.43925666809082 0.5168539325842697 0.391304347826087\n",
      "118 4.495078086853027 0.5730337078651685 0.391304347826087\n",
      "119 4.421816825866699 0.4157303370786517 0.391304347826087\n",
      "120 4.44001579284668 0.4157303370786517 0.391304347826087\n",
      "121 4.246726036071777 0.48314606741573035 0.391304347826087\n",
      "122 4.455007553100586 0.47191011235955055 0.391304347826087\n",
      "123 4.453767776489258 0.47191011235955055 0.391304347826087\n",
      "124 4.498946666717529 0.47191011235955055 0.391304347826087\n",
      "125 4.231891632080078 0.5393258426966292 0.391304347826087\n",
      "126 4.351365566253662 0.42696629213483145 0.391304347826087\n",
      "127 4.555830478668213 0.449438202247191 0.391304347826087\n",
      "128 4.586289405822754 0.39325842696629215 0.391304347826087\n",
      "129 4.511071681976318 0.550561797752809 0.391304347826087\n",
      "130 4.61165189743042 0.48314606741573035 0.391304347826087\n",
      "131 4.485195159912109 0.47191011235955055 0.391304347826087\n",
      "132 4.436784267425537 0.5168539325842697 0.391304347826087\n",
      "133 4.379965305328369 0.5168539325842697 0.391304347826087\n",
      "134 4.3156914710998535 0.47191011235955055 0.391304347826087\n",
      "135 4.524356842041016 0.5056179775280899 0.391304347826087\n",
      "136 4.500805854797363 0.5280898876404494 0.391304347826087\n",
      "137 4.3922295570373535 0.4943820224719101 0.391304347826087\n",
      "138 4.392477512359619 0.5955056179775281 0.391304347826087\n",
      "139 4.539336681365967 0.48314606741573035 0.391304347826087\n",
      "140 4.518447399139404 0.5280898876404494 0.391304347826087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 4.4250874519348145 0.47191011235955055 0.391304347826087\n",
      "142 4.473495006561279 0.4606741573033708 0.391304347826087\n",
      "143 4.29237174987793 0.47191011235955055 0.391304347826087\n",
      "144 4.401815414428711 0.42696629213483145 0.391304347826087\n",
      "145 4.369826316833496 0.4606741573033708 0.391304347826087\n",
      "146 4.411806106567383 0.4606741573033708 0.391304347826087\n",
      "147 4.523090362548828 0.5280898876404494 0.391304347826087\n",
      "148 4.510478496551514 0.4943820224719101 0.391304347826087\n",
      "149 4.482841968536377 0.47191011235955055 0.391304347826087\n",
      "150 4.314613342285156 0.4943820224719101 0.391304347826087\n",
      "151 4.3772053718566895 0.449438202247191 0.391304347826087\n",
      "152 4.507637023925781 0.5168539325842697 0.391304347826087\n",
      "153 4.351282119750977 0.43820224719101125 0.391304347826087\n",
      "154 4.298178195953369 0.5280898876404494 0.391304347826087\n",
      "155 4.436042785644531 0.47191011235955055 0.391304347826087\n",
      "156 4.399289131164551 0.48314606741573035 0.391304347826087\n",
      "157 4.60286808013916 0.449438202247191 0.391304347826087\n",
      "158 4.389991283416748 0.5280898876404494 0.391304347826087\n",
      "159 4.701142311096191 0.4606741573033708 0.391304347826087\n",
      "160 4.590859413146973 0.38202247191011235 0.391304347826087\n",
      "161 4.411036014556885 0.5393258426966292 0.391304347826087\n",
      "162 4.454516410827637 0.48314606741573035 0.391304347826087\n",
      "163 4.55284309387207 0.48314606741573035 0.391304347826087\n",
      "164 4.700019836425781 0.4044943820224719 0.391304347826087\n",
      "165 4.5923237800598145 0.5056179775280899 0.391304347826087\n",
      "166 4.263294219970703 0.47191011235955055 0.391304347826087\n",
      "167 4.557992458343506 0.5168539325842697 0.391304347826087\n",
      "168 4.4709978103637695 0.449438202247191 0.391304347826087\n",
      "169 4.4768757820129395 0.43820224719101125 0.391304347826087\n",
      "170 4.46606969833374 0.4606741573033708 0.391304347826087\n",
      "171 4.411667346954346 0.4943820224719101 0.391304347826087\n",
      "172 4.414278030395508 0.5056179775280899 0.391304347826087\n",
      "173 4.448451042175293 0.5280898876404494 0.391304347826087\n",
      "174 4.318792343139648 0.449438202247191 0.391304347826087\n",
      "175 4.634634494781494 0.43820224719101125 0.391304347826087\n",
      "176 4.444843292236328 0.43820224719101125 0.391304347826087\n",
      "177 4.511153697967529 0.4943820224719101 0.391304347826087\n",
      "178 4.549017906188965 0.449438202247191 0.391304347826087\n",
      "179 4.4035797119140625 0.5168539325842697 0.391304347826087\n",
      "180 4.290126800537109 0.47191011235955055 0.391304347826087\n",
      "181 4.370241641998291 0.5168539325842697 0.391304347826087\n",
      "182 4.428465843200684 0.48314606741573035 0.391304347826087\n",
      "183 4.3755340576171875 0.47191011235955055 0.391304347826087\n",
      "184 4.319797039031982 0.48314606741573035 0.391304347826087\n",
      "185 4.533654689788818 0.47191011235955055 0.391304347826087\n",
      "186 4.456755638122559 0.550561797752809 0.391304347826087\n",
      "187 4.659976959228516 0.48314606741573035 0.391304347826087\n",
      "188 4.581727981567383 0.48314606741573035 0.391304347826087\n",
      "189 4.299496650695801 0.4606741573033708 0.391304347826087\n",
      "190 4.604140281677246 0.4606741573033708 0.391304347826087\n",
      "191 4.482339859008789 0.4943820224719101 0.391304347826087\n",
      "192 4.513230323791504 0.5617977528089888 0.391304347826087\n",
      "193 4.565457344055176 0.4943820224719101 0.391304347826087\n",
      "194 4.41390323638916 0.4606741573033708 0.391304347826087\n",
      "195 4.266057014465332 0.5168539325842697 0.391304347826087\n",
      "196 4.4832763671875 0.449438202247191 0.391304347826087\n",
      "197 4.26219367980957 0.48314606741573035 0.391304347826087\n",
      "198 4.306203842163086 0.4606741573033708 0.391304347826087\n",
      "199 4.373390197753906 0.4943820224719101 0.391304347826087\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural_pois.train()\n",
    "    mu = neural_pois(X_tr)\n",
    "    lossA_pois = crit_pois(mu[:,[0]],y_trA)\n",
    "    lossB_pois = crit_pois(mu[:,[1]],y_trB)\n",
    "    loss_pois = lossA_pois+lossB_pois    \n",
    "    tend_acc_tr = util.tend_acc_pois(mu.data.numpy(),y_train)\n",
    "    # evaluate\n",
    "    neural_pois.eval()\n",
    "    mu = neural_pois(X_te)\n",
    "    tend_acc_val = util.tend_acc_pois(mu.data.numpy(),y_test)\n",
    "    print(epoch, loss_pois.item(),tend_acc_tr,tend_acc_val)\n",
    "    # update\n",
    "    optimizer_pois.zero_grad()\n",
    "    loss_pois.backward()\n",
    "    optimizer_pois.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pois.eval()\n",
    "mu=neural_pois(X_te).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.12700998]\n",
      " [0.         1.         0.10558353]\n",
      " [1.         0.         0.09535259]\n",
      " [1.         2.         0.08458886]\n",
      " [0.         0.         0.07926671]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.11458894]\n",
      " [1.         2.         0.0874247 ]\n",
      " [0.         1.         0.08193821]\n",
      " [2.         1.         0.08012516]\n",
      " [1.         0.         0.07509677]]\n",
      "wrong prediction for [1 3]\n",
      "candidates \n",
      " [[1.         1.         0.10815176]\n",
      " [2.         1.         0.08889735]\n",
      " [1.         2.         0.07822489]\n",
      " [1.         0.         0.07476395]\n",
      " [0.         1.         0.06578825]]\n",
      "right prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.11944042]\n",
      " [0.         1.         0.09021496]\n",
      " [1.         2.         0.08719963]\n",
      " [1.         0.         0.08180088]\n",
      " [2.         1.         0.07906679]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.11366611]\n",
      " [1.         2.         0.08491191]\n",
      " [2.         1.         0.0830419 ]\n",
      " [0.         1.         0.07779196]\n",
      " [1.         0.         0.07607875]]\n",
      "wrong prediction for [4 2]\n",
      "candidates \n",
      " [[1.         1.         0.10516824]\n",
      " [1.         2.         0.08936527]\n",
      " [2.         1.         0.07701826]\n",
      " [0.         1.         0.07180348]\n",
      " [2.         2.         0.06544521]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.12499663]\n",
      " [0.         1.         0.09696377]\n",
      " [1.         0.         0.09412817]\n",
      " [1.         2.         0.08299406]\n",
      " [2.         1.         0.08056699]]\n",
      "wrong prediction for [2 3]\n",
      "candidates \n",
      " [[1.         1.         0.11425556]\n",
      " [1.         2.         0.08751067]\n",
      " [0.         1.         0.08152579]\n",
      " [2.         1.         0.08006259]\n",
      " [1.         0.         0.07458709]]\n",
      "right prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.1110087 ]\n",
      " [1.         2.         0.0887541 ]\n",
      " [2.         1.         0.07865895]\n",
      " [0.         1.         0.0783314 ]\n",
      " [1.         0.         0.06942175]]\n",
      "wrong prediction for [2 4]\n",
      "candidates \n",
      " [[1.         1.         0.12496195]\n",
      " [0.         1.         0.10016714]\n",
      " [1.         0.         0.09166415]\n",
      " [1.         2.         0.08517772]\n",
      " [2.         1.         0.07794716]]\n",
      "wrong prediction for [5 2]\n",
      "candidates \n",
      " [[1.         1.         0.11313196]\n",
      " [1.         2.         0.0878634 ]\n",
      " [0.         1.         0.08025988]\n",
      " [2.         1.         0.07973373]\n",
      " [1.         0.         0.07283373]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.1263256 ]\n",
      " [0.         1.         0.09895557]\n",
      " [1.         0.         0.09754676]\n",
      " [1.         2.         0.08179747]\n",
      " [2.         1.         0.08063294]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.10359999]\n",
      " [1.         2.         0.08588253]\n",
      " [2.         1.         0.08074014]\n",
      " [2.         2.         0.06693213]\n",
      " [0.         1.         0.06646606]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.12526965]\n",
      " [0.         1.         0.10252485]\n",
      " [1.         0.         0.09128652]\n",
      " [1.         2.         0.08595182]\n",
      " [2.         1.         0.07653015]]\n",
      "wrong prediction for [1 7]\n",
      "candidates \n",
      " [[1.         1.         0.11637325]\n",
      " [1.         2.         0.08399658]\n",
      " [2.         1.         0.08362543]\n",
      " [0.         1.         0.08097258]\n",
      " [1.         0.         0.08061478]]\n",
      "right prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.1153128 ]\n",
      " [1.         2.         0.09081735]\n",
      " [0.         1.         0.08821484]\n",
      " [2.         1.         0.07536737]\n",
      " [1.         0.         0.07320761]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.11935969]\n",
      " [0.         1.         0.08583319]\n",
      " [1.         0.         0.08499843]\n",
      " [1.         2.         0.08380588]\n",
      " [2.         1.         0.08299083]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.12711981]\n",
      " [1.         0.         0.10353705]\n",
      " [0.         1.         0.09701248]\n",
      " [2.         1.         0.0832854 ]\n",
      " [0.         0.         0.07901511]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.10129602]\n",
      " [1.         2.         0.08808787]\n",
      " [2.         1.         0.07737344]\n",
      " [2.         2.         0.06728459]\n",
      " [0.         1.         0.06630753]]\n",
      "right prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.12602603]\n",
      " [0.         1.         0.10039814]\n",
      " [1.         0.         0.09518393]\n",
      " [1.         2.         0.08343089]\n",
      " [2.         1.         0.07909788]]\n",
      "wrong prediction for [0 4]\n",
      "candidates \n",
      " [[1.         1.         0.12054908]\n",
      " [0.         1.         0.09100043]\n",
      " [1.         2.         0.08616384]\n",
      " [1.         0.         0.08432818]\n",
      " [2.         1.         0.07984621]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.1234396 ]\n",
      " [0.         1.         0.09255026]\n",
      " [1.         0.         0.09241526]\n",
      " [1.         2.         0.08243949]\n",
      " [2.         1.         0.08231925]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.11353952]\n",
      " [2.         1.         0.0845281 ]\n",
      " [1.         2.         0.08344861]\n",
      " [1.         0.         0.07724049]\n",
      " [0.         1.         0.07625407]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.391304347826087"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs=util.calc_pois_probs(mu[:,0],mu[:,1])\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Poisson regression suffers from the same problem as negative binomial regression with fixed dispersion $\\alpha$ (it seems to memorize the most frequent outcomes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_gr.copy(),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamA_def_mean = data_train[\"teamA_def_val\"].mean()\n",
    "teamA_def_std = data_train[\"teamA_def_val\"].std()\n",
    "teamA_off_mean = data_train[\"teamA_off_val\"].mean()\n",
    "teamA_off_std = data_train[\"teamA_off_val\"].std()\n",
    "\n",
    "teamB_def_mean = data_train[\"teamB_def_val\"].mean()\n",
    "teamB_def_std = data_train[\"teamB_def_val\"].std()\n",
    "teamB_off_mean = data_train[\"teamB_off_val\"].mean()\n",
    "teamB_off_std = data_train[\"teamB_off_val\"].std()\n",
    "\n",
    "teamA_frag_mean = data_train[\"teamA_frag\"].mean()\n",
    "teamA_frag_std = data_train[\"teamA_frag\"].std()\n",
    "\n",
    "teamB_frag_mean = data_train[\"teamB_frag\"].mean()\n",
    "teamB_frag_std = data_train[\"teamB_frag\"].std()\n",
    "\n",
    "teamA_age_mean = data_train[\"teamA_age\"].mean()\n",
    "teamA_age_std = data_train[\"teamA_age\"].std()\n",
    "\n",
    "teamB_age_mean = data_train[\"teamB_age\"].mean()\n",
    "teamB_age_std = data_train[\"teamB_age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale some features\n",
    "data_train[\"teamA_def_val\"]=(data_train[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_train[\"teamA_off_val\"]=(data_train[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_train[\"teamB_def_val\"]=(data_train[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_train[\"teamB_off_val\"]=(data_train[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_train[\"teamA_frag\"]=(data_train[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_train[\"teamB_frag\"]=(data_train[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_train[\"teamA_age\"]=(data_train[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_train[\"teamB_age\"]=(data_train[\"teamB_age\"]-teamB_age_mean)/teamB_age_std\n",
    "\n",
    "# scale test features\n",
    "data_test[\"teamA_def_val\"]=(data_test[\"teamA_def_val\"]-teamA_def_mean)/teamA_def_std\n",
    "data_test[\"teamA_off_val\"]=(data_test[\"teamA_off_val\"]-teamA_off_mean)/teamA_off_std\n",
    "data_test[\"teamB_def_val\"]=(data_test[\"teamB_def_val\"]-teamB_def_mean)/teamB_def_std\n",
    "data_test[\"teamB_off_val\"]=(data_test[\"teamB_off_val\"]-teamB_off_mean)/teamB_off_std\n",
    "data_test[\"teamA_frag\"]=(data_test[\"teamA_frag\"]-teamA_frag_mean)/teamA_frag_std\n",
    "data_test[\"teamB_frag\"]=(data_test[\"teamB_frag\"]-teamB_frag_mean)/teamB_frag_std\n",
    "data_test[\"teamA_age\"]=(data_test[\"teamA_age\"]-teamA_age_mean)/teamA_age_std\n",
    "data_test[\"teamB_age\"]=(data_test[\"teamB_age\"]-teamB_age_mean)/teamB_age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gametype</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>335.0</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.286567</td>\n",
       "      <td>1.086567</td>\n",
       "      <td>1.320337e-15</td>\n",
       "      <td>9.968809e-16</td>\n",
       "      <td>-8.948066e-18</td>\n",
       "      <td>-1.378665e-16</td>\n",
       "      <td>2.651279e-18</td>\n",
       "      <td>-2.121023e-17</td>\n",
       "      <td>1.007486e-16</td>\n",
       "      <td>1.643793e-16</td>\n",
       "      <td>0.932388</td>\n",
       "      <td>0.862776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238709</td>\n",
       "      <td>1.108608</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.138333</td>\n",
       "      <td>1.183526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.235472e+00</td>\n",
       "      <td>-3.528631e+00</td>\n",
       "      <td>-8.703205e-01</td>\n",
       "      <td>-7.889466e-01</td>\n",
       "      <td>-8.711014e-01</td>\n",
       "      <td>-8.174861e-01</td>\n",
       "      <td>-2.995404e+00</td>\n",
       "      <td>-2.334347e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.323328e-01</td>\n",
       "      <td>-5.730365e-01</td>\n",
       "      <td>-7.064595e-01</td>\n",
       "      <td>-6.547845e-01</td>\n",
       "      <td>-7.106865e-01</td>\n",
       "      <td>-6.816657e-01</td>\n",
       "      <td>-5.853464e-01</td>\n",
       "      <td>-7.101303e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.558895e-02</td>\n",
       "      <td>7.048935e-02</td>\n",
       "      <td>-3.413839e-01</td>\n",
       "      <td>-3.774790e-01</td>\n",
       "      <td>-4.006637e-01</td>\n",
       "      <td>-3.833653e-01</td>\n",
       "      <td>7.194202e-02</td>\n",
       "      <td>2.643999e-01</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.613481e-01</td>\n",
       "      <td>6.330928e-01</td>\n",
       "      <td>2.871698e-01</td>\n",
       "      <td>1.106148e-01</td>\n",
       "      <td>3.749480e-01</td>\n",
       "      <td>2.347915e-01</td>\n",
       "      <td>9.483266e-01</td>\n",
       "      <td>9.140867e-01</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.283184e+00</td>\n",
       "      <td>2.243834e+00</td>\n",
       "      <td>3.993425e+00</td>\n",
       "      <td>4.756678e+00</td>\n",
       "      <td>3.481151e+00</td>\n",
       "      <td>4.638255e+00</td>\n",
       "      <td>1.605615e+00</td>\n",
       "      <td>1.563774e+00</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gametype     resultA     resultB     teamA_age     teamB_age  \\\n",
       "count     335.0  335.000000  335.000000  3.350000e+02  3.350000e+02   \n",
       "mean        6.0    1.286567    1.086567  1.320337e-15  9.968809e-16   \n",
       "std         0.0    1.238709    1.108608  1.000000e+00  1.000000e+00   \n",
       "min         6.0    0.000000    0.000000 -3.235472e+00 -3.528631e+00   \n",
       "25%         6.0    0.000000    0.000000 -6.323328e-01 -5.730365e-01   \n",
       "50%         6.0    1.000000    1.000000 -1.558895e-02  7.048935e-02   \n",
       "75%         6.0    2.000000    2.000000  7.613481e-01  6.330928e-01   \n",
       "max         6.0    7.000000    5.000000  2.283184e+00  2.243834e+00   \n",
       "\n",
       "       teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  \\\n",
       "count   3.350000e+02   3.350000e+02   3.350000e+02   3.350000e+02   \n",
       "mean   -8.948066e-18  -1.378665e-16   2.651279e-18  -2.121023e-17   \n",
       "std     1.000000e+00   1.000000e+00   1.000000e+00   1.000000e+00   \n",
       "min    -8.703205e-01  -7.889466e-01  -8.711014e-01  -8.174861e-01   \n",
       "25%    -7.064595e-01  -6.547845e-01  -7.106865e-01  -6.816657e-01   \n",
       "50%    -3.413839e-01  -3.774790e-01  -4.006637e-01  -3.833653e-01   \n",
       "75%     2.871698e-01   1.106148e-01   3.749480e-01   2.347915e-01   \n",
       "max     3.993425e+00   4.756678e+00   3.481151e+00   4.638255e+00   \n",
       "\n",
       "         teamA_frag    teamB_frag  past_resultA  past_resultB  \n",
       "count  3.350000e+02  3.350000e+02    335.000000    335.000000  \n",
       "mean   1.007486e-16  1.643793e-16      0.932388      0.862776  \n",
       "std    1.000000e+00  1.000000e+00      1.138333      1.183526  \n",
       "min   -2.995404e+00 -2.334347e+00      0.000000      0.000000  \n",
       "25%   -5.853464e-01 -7.101303e-01      0.000000      0.000000  \n",
       "50%    7.194202e-02  2.643999e-01      0.950000      0.050000  \n",
       "75%    9.483266e-01  9.140867e-01      1.900000      1.120000  \n",
       "max    1.605615e+00  1.563774e+00      4.900000      5.700000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]\n",
    "\n",
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[col].values\n",
    "y_train = data_train[[\"resultA\",\"resultB\"]].values\n",
    "X_test = data_test[col].values\n",
    "y_test = data_test[[\"resultA\",\"resultB\"]].values\n",
    "\n",
    "X_tr = torch.from_numpy(X_train).float()\n",
    "y_trA = torch.from_numpy(y_train[:,[0]]).float()\n",
    "y_trB = torch.from_numpy(y_train[:,[1]]).float()\n",
    "X_te = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = NBNLLLoss(eps=1e-4,verbose=False)\n",
    "neural = NBNet(len(col),30,20,4,0.3)\n",
    "optimizer = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.02915096282959 0.35522388059701493 0.3333333333333333\n",
      "1 2.984318971633911 0.3582089552238806 0.40476190476190477\n",
      "2 2.967223644256592 0.34328358208955223 0.39285714285714285\n",
      "3 2.9429664611816406 0.382089552238806 0.40476190476190477\n",
      "4 2.93709659576416 0.39104477611940297 0.40476190476190477\n",
      "5 2.9223203659057617 0.4298507462686567 0.4166666666666667\n",
      "6 2.9139623641967773 0.4298507462686567 0.4166666666666667\n",
      "7 2.9042115211486816 0.43582089552238806 0.4166666666666667\n",
      "8 2.9101028442382812 0.43283582089552236 0.40476190476190477\n",
      "9 2.8892102241516113 0.43582089552238806 0.42857142857142855\n",
      "10 2.9018993377685547 0.44477611940298506 0.42857142857142855\n",
      "11 2.882643699645996 0.4388059701492537 0.42857142857142855\n",
      "12 2.888030529022217 0.46567164179104475 0.42857142857142855\n",
      "13 2.8870251178741455 0.4537313432835821 0.42857142857142855\n",
      "14 2.8747756481170654 0.4388059701492537 0.44047619047619047\n",
      "15 2.8738889694213867 0.46567164179104475 0.44047619047619047\n",
      "16 2.8619143962860107 0.4746268656716418 0.44047619047619047\n",
      "17 2.8807592391967773 0.4746268656716418 0.4523809523809524\n",
      "18 2.873826026916504 0.45671641791044776 0.4642857142857143\n",
      "19 2.865204334259033 0.4597014925373134 0.4642857142857143\n",
      "20 2.864415168762207 0.4626865671641791 0.4642857142857143\n",
      "21 2.8373312950134277 0.4716417910447761 0.4642857142857143\n",
      "22 2.852071762084961 0.48656716417910445 0.47619047619047616\n",
      "23 2.8375682830810547 0.49850746268656715 0.47619047619047616\n",
      "24 2.8386433124542236 0.4925373134328358 0.4880952380952381\n",
      "25 2.8276944160461426 0.4835820895522388 0.4880952380952381\n",
      "26 2.830808162689209 0.4835820895522388 0.5\n",
      "27 2.8078866004943848 0.5223880597014925 0.5238095238095238\n",
      "28 2.8248915672302246 0.4925373134328358 0.5357142857142857\n",
      "29 2.8038883209228516 0.5014925373134328 0.5357142857142857\n",
      "30 2.800959587097168 0.4746268656716418 0.5357142857142857\n",
      "31 2.8022546768188477 0.5014925373134328 0.5238095238095238\n",
      "32 2.7721171379089355 0.5014925373134328 0.5238095238095238\n",
      "33 2.789639949798584 0.5044776119402985 0.5357142857142857\n",
      "34 2.818169116973877 0.4746268656716418 0.5357142857142857\n",
      "35 2.8311824798583984 0.4716417910447761 0.5119047619047619\n",
      "36 2.7924861907958984 0.5253731343283582 0.5238095238095238\n",
      "37 2.797701597213745 0.4835820895522388 0.5119047619047619\n",
      "38 2.8061208724975586 0.4746268656716418 0.5119047619047619\n",
      "39 2.8135147094726562 0.5014925373134328 0.5119047619047619\n",
      "40 2.8073506355285645 0.48955223880597015 0.5357142857142857\n",
      "41 2.8209452629089355 0.46865671641791046 0.5238095238095238\n",
      "42 2.8074731826782227 0.5104477611940299 0.5238095238095238\n",
      "43 2.786597728729248 0.5014925373134328 0.5357142857142857\n",
      "44 2.77394437789917 0.5164179104477612 0.5238095238095238\n",
      "45 2.7947182655334473 0.4925373134328358 0.5238095238095238\n",
      "46 2.7968907356262207 0.5014925373134328 0.5357142857142857\n",
      "47 2.7913460731506348 0.49850746268656715 0.5357142857142857\n",
      "48 2.777369499206543 0.4925373134328358 0.5238095238095238\n",
      "49 2.7976937294006348 0.4925373134328358 0.5357142857142857\n",
      "50 2.7776899337768555 0.5014925373134328 0.5357142857142857\n",
      "51 2.7860608100891113 0.5044776119402985 0.5357142857142857\n",
      "52 2.7979602813720703 0.5283582089552239 0.5357142857142857\n",
      "53 2.7706668376922607 0.5283582089552239 0.5119047619047619\n",
      "54 2.8065943717956543 0.48656716417910445 0.5119047619047619\n",
      "55 2.752408504486084 0.5343283582089552 0.5119047619047619\n",
      "56 2.7546181678771973 0.5343283582089552 0.5119047619047619\n",
      "57 2.753626823425293 0.5223880597014925 0.5357142857142857\n",
      "58 2.765519618988037 0.4925373134328358 0.5238095238095238\n",
      "59 2.7499332427978516 0.5253731343283582 0.5238095238095238\n",
      "60 2.7520508766174316 0.5044776119402985 0.5119047619047619\n",
      "61 2.718883752822876 0.5044776119402985 0.5119047619047619\n",
      "62 2.7374699115753174 0.5014925373134328 0.5238095238095238\n",
      "63 2.7558581829071045 0.5164179104477612 0.5357142857142857\n",
      "64 2.7320239543914795 0.5253731343283582 0.5357142857142857\n",
      "65 2.7620491981506348 0.5134328358208955 0.5357142857142857\n",
      "66 2.7465643882751465 0.5432835820895522 0.5119047619047619\n",
      "67 2.760350465774536 0.5074626865671642 0.5238095238095238\n",
      "68 2.738035202026367 0.5134328358208955 0.5119047619047619\n",
      "69 2.7250261306762695 0.5283582089552239 0.5119047619047619\n",
      "70 2.755438804626465 0.5283582089552239 0.5119047619047619\n",
      "71 2.7409768104553223 0.5134328358208955 0.5119047619047619\n",
      "72 2.7499799728393555 0.49850746268656715 0.5119047619047619\n",
      "73 2.7610204219818115 0.48656716417910445 0.5119047619047619\n",
      "74 2.765373706817627 0.5194029850746269 0.5119047619047619\n",
      "75 2.7232918739318848 0.5402985074626866 0.5119047619047619\n",
      "76 2.771719455718994 0.49850746268656715 0.5238095238095238\n",
      "77 2.7170252799987793 0.5014925373134328 0.5238095238095238\n",
      "78 2.731135845184326 0.5164179104477612 0.5357142857142857\n",
      "79 2.7479543685913086 0.5134328358208955 0.5238095238095238\n",
      "80 2.738226890563965 0.5104477611940299 0.5119047619047619\n",
      "81 2.750546932220459 0.5044776119402985 0.5119047619047619\n",
      "82 2.755251884460449 0.49850746268656715 0.5119047619047619\n",
      "83 2.7565529346466064 0.5253731343283582 0.5119047619047619\n",
      "84 2.730966806411743 0.5164179104477612 0.5238095238095238\n",
      "85 2.759641408920288 0.5253731343283582 0.5119047619047619\n",
      "86 2.711728572845459 0.5313432835820896 0.5238095238095238\n",
      "87 2.7452621459960938 0.5313432835820896 0.5119047619047619\n",
      "88 2.737865686416626 0.5074626865671642 0.5119047619047619\n",
      "89 2.7132134437561035 0.5223880597014925 0.5238095238095238\n",
      "90 2.7202210426330566 0.5194029850746269 0.5119047619047619\n",
      "91 2.7536702156066895 0.5164179104477612 0.5119047619047619\n",
      "92 2.7393112182617188 0.49850746268656715 0.5119047619047619\n",
      "93 2.704057455062866 0.5283582089552239 0.5119047619047619\n",
      "94 2.732797622680664 0.5343283582089552 0.5238095238095238\n",
      "95 2.7377870082855225 0.5044776119402985 0.5119047619047619\n",
      "96 2.7356653213500977 0.5253731343283582 0.5119047619047619\n",
      "97 2.7457263469696045 0.5253731343283582 0.5119047619047619\n",
      "98 2.7224981784820557 0.5373134328358209 0.5119047619047619\n",
      "99 2.7370715141296387 0.5164179104477612 0.5238095238095238\n",
      "100 2.695404529571533 0.5283582089552239 0.5119047619047619\n",
      "101 2.7233500480651855 0.5104477611940299 0.5357142857142857\n",
      "102 2.715292453765869 0.5253731343283582 0.5238095238095238\n",
      "103 2.7285075187683105 0.5044776119402985 0.5238095238095238\n",
      "104 2.732252359390259 0.5074626865671642 0.5238095238095238\n",
      "105 2.722628116607666 0.5343283582089552 0.5238095238095238\n",
      "106 2.741234064102173 0.5104477611940299 0.5238095238095238\n",
      "107 2.717968463897705 0.5044776119402985 0.5238095238095238\n",
      "108 2.757449150085449 0.5074626865671642 0.5238095238095238\n",
      "109 2.702792167663574 0.5194029850746269 0.5238095238095238\n",
      "110 2.7118782997131348 0.5313432835820896 0.5119047619047619\n",
      "111 2.7216644287109375 0.5223880597014925 0.5238095238095238\n",
      "112 2.73423433303833 0.48955223880597015 0.5238095238095238\n",
      "113 2.713533878326416 0.5402985074626866 0.5238095238095238\n",
      "114 2.7199902534484863 0.5164179104477612 0.5238095238095238\n",
      "115 2.743771553039551 0.48955223880597015 0.5238095238095238\n",
      "116 2.7567596435546875 0.5104477611940299 0.5238095238095238\n",
      "117 2.719599485397339 0.5283582089552239 0.5238095238095238\n",
      "118 2.6982953548431396 0.5164179104477612 0.5238095238095238\n",
      "119 2.7290048599243164 0.5283582089552239 0.5238095238095238\n",
      "120 2.6832985877990723 0.5552238805970149 0.5238095238095238\n",
      "121 2.707310676574707 0.5253731343283582 0.5238095238095238\n",
      "122 2.7035138607025146 0.5373134328358209 0.5238095238095238\n",
      "123 2.717951774597168 0.5283582089552239 0.5238095238095238\n",
      "124 2.705883026123047 0.5313432835820896 0.5238095238095238\n",
      "125 2.723332405090332 0.5164179104477612 0.5238095238095238\n",
      "126 2.693840503692627 0.5552238805970149 0.5238095238095238\n",
      "127 2.74249529838562 0.5223880597014925 0.5238095238095238\n",
      "128 2.6928811073303223 0.5343283582089552 0.5238095238095238\n",
      "129 2.6919398307800293 0.5223880597014925 0.5238095238095238\n",
      "130 2.6900367736816406 0.5313432835820896 0.5238095238095238\n",
      "131 2.70369291305542 0.5432835820895522 0.5238095238095238\n",
      "132 2.6804559230804443 0.5194029850746269 0.5238095238095238\n",
      "133 2.677835464477539 0.5223880597014925 0.5238095238095238\n",
      "134 2.67720365524292 0.5432835820895522 0.5119047619047619\n",
      "135 2.706361770629883 0.5164179104477612 0.5238095238095238\n",
      "136 2.7382941246032715 0.5223880597014925 0.5238095238095238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 2.692866802215576 0.5194029850746269 0.5238095238095238\n",
      "138 2.7241668701171875 0.5164179104477612 0.5119047619047619\n",
      "139 2.6921772956848145 0.5134328358208955 0.5119047619047619\n",
      "140 2.7062034606933594 0.5373134328358209 0.5238095238095238\n",
      "141 2.7050576210021973 0.5373134328358209 0.5357142857142857\n",
      "142 2.6868677139282227 0.5402985074626866 0.5119047619047619\n",
      "143 2.697754144668579 0.5223880597014925 0.5119047619047619\n",
      "144 2.7013378143310547 0.5432835820895522 0.5119047619047619\n",
      "145 2.6843247413635254 0.5343283582089552 0.5119047619047619\n",
      "146 2.7088630199432373 0.5164179104477612 0.5238095238095238\n",
      "147 2.6830239295959473 0.5313432835820896 0.5238095238095238\n",
      "148 2.7178354263305664 0.5283582089552239 0.5238095238095238\n",
      "149 2.692103147506714 0.5223880597014925 0.5357142857142857\n",
      "150 2.698939561843872 0.5223880597014925 0.5357142857142857\n",
      "151 2.6996564865112305 0.5104477611940299 0.5119047619047619\n",
      "152 2.685128927230835 0.5283582089552239 0.5119047619047619\n",
      "153 2.6946287155151367 0.5402985074626866 0.5119047619047619\n",
      "154 2.6908154487609863 0.5373134328358209 0.5357142857142857\n",
      "155 2.698806047439575 0.5194029850746269 0.5119047619047619\n",
      "156 2.6867270469665527 0.5164179104477612 0.5119047619047619\n",
      "157 2.7111752033233643 0.5253731343283582 0.5238095238095238\n",
      "158 2.6921305656433105 0.5223880597014925 0.5119047619047619\n",
      "159 2.7143397331237793 0.5253731343283582 0.5119047619047619\n",
      "160 2.691746473312378 0.5313432835820896 0.5119047619047619\n",
      "161 2.696415901184082 0.4955223880597015 0.5119047619047619\n",
      "162 2.6884474754333496 0.4955223880597015 0.5238095238095238\n",
      "163 2.7019410133361816 0.5164179104477612 0.5238095238095238\n",
      "164 2.7138805389404297 0.5402985074626866 0.5238095238095238\n",
      "165 2.6817219257354736 0.5343283582089552 0.5119047619047619\n",
      "166 2.692171573638916 0.5283582089552239 0.5238095238095238\n",
      "167 2.707531690597534 0.5432835820895522 0.5119047619047619\n",
      "168 2.690317153930664 0.5104477611940299 0.5119047619047619\n",
      "169 2.664468288421631 0.5313432835820896 0.5119047619047619\n",
      "170 2.6938555240631104 0.5283582089552239 0.5119047619047619\n",
      "171 2.667682647705078 0.5432835820895522 0.5119047619047619\n",
      "172 2.7059364318847656 0.5343283582089552 0.5119047619047619\n",
      "173 2.7215397357940674 0.5223880597014925 0.5119047619047619\n",
      "174 2.7036120891571045 0.5044776119402985 0.5119047619047619\n",
      "175 2.7051305770874023 0.5373134328358209 0.5119047619047619\n",
      "176 2.6849441528320312 0.5462686567164179 0.5238095238095238\n",
      "177 2.703610420227051 0.5343283582089552 0.5238095238095238\n",
      "178 2.6632637977600098 0.5313432835820896 0.5238095238095238\n",
      "179 2.698244571685791 0.5194029850746269 0.5238095238095238\n",
      "180 2.6611156463623047 0.5522388059701493 0.5238095238095238\n",
      "181 2.6733222007751465 0.5343283582089552 0.5119047619047619\n",
      "182 2.696995258331299 0.5432835820895522 0.5357142857142857\n",
      "183 2.672379493713379 0.5522388059701493 0.5238095238095238\n",
      "184 2.6889050006866455 0.5223880597014925 0.5357142857142857\n",
      "185 2.664944887161255 0.5194029850746269 0.5238095238095238\n",
      "186 2.6868090629577637 0.5492537313432836 0.5238095238095238\n",
      "187 2.6549525260925293 0.5432835820895522 0.5238095238095238\n",
      "188 2.6457033157348633 0.5462686567164179 0.5357142857142857\n",
      "189 2.6889350414276123 0.5223880597014925 0.5238095238095238\n",
      "190 2.6661746501922607 0.5402985074626866 0.5238095238095238\n",
      "191 2.6874072551727295 0.5194029850746269 0.5238095238095238\n",
      "192 2.6529290676116943 0.5432835820895522 0.5357142857142857\n",
      "193 2.673866033554077 0.5253731343283582 0.5357142857142857\n",
      "194 2.6567494869232178 0.564179104477612 0.5238095238095238\n",
      "195 2.668632984161377 0.5253731343283582 0.5238095238095238\n",
      "196 2.6529507637023926 0.5402985074626866 0.5238095238095238\n",
      "197 2.6601057052612305 0.5223880597014925 0.5238095238095238\n",
      "198 2.6970245838165283 0.5343283582089552 0.5238095238095238\n",
      "199 2.677168130874634 0.5313432835820896 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural.train()\n",
    "    muA,alphaA,muB,alphaB = neural(X_tr)\n",
    "    lossA = crit(muA,alphaA,y_trA)\n",
    "    lossB = crit(muB,alphaB,y_trB)\n",
    "    loss = lossA+lossB\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_tr = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_train)\n",
    "    # evaluate\n",
    "    neural.eval()\n",
    "    muA,alphaA,muB,alphaB = neural(X_te)\n",
    "    muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "    tend_acc_val = util.tend_acc_nb(muA,alphaA,muB,alphaB,y_test)\n",
    "    # update\n",
    "    print(epoch,loss.item(),tend_acc_tr,tend_acc_val)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural.eval()\n",
    "muA,alphaA,muB,alphaB=neural(X_te)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.14152381]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[1.         0.         0.12850194]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.15107851]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         0.         0.14418252]]\n",
      "wrong prediction for [2 2]\n",
      "candidates \n",
      " [[1.         0.         0.16262281]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[0.         1.         0.12069098]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.16835176]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.13468313]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.18738873]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         0.         0.14478494]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[1.         0.         0.16787467]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.13282682]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.16680049]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.16430027]]\n",
      "wrong prediction for [6 1]\n",
      "candidates \n",
      " [[1.         0.         0.12891476]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         1.         0.19691519]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         0.         0.18326917]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.15223191]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[1.         0.         0.15970055]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[1.         0.         0.13671778]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.13382301]]\n",
      "wrong prediction for [1 3]\n",
      "candidates \n",
      " [[1.         0.         0.12166692]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         0.         0.13751306]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.13449825]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.12843147]]\n",
      "wrong prediction for [4 1]\n",
      "candidates \n",
      " [[2.         0.         0.11769068]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.19516231]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.15381545]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[0.         1.         0.18503748]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.14053493]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[2.         0.         0.12228381]]\n",
      "wrong prediction for [0 3]\n",
      "candidates \n",
      " [[0.         1.         0.14670532]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         0.         0.15261097]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.12020431]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[0.         0.         0.16399334]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.13444366]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.12360547]]\n",
      "wrong prediction for [1 5]\n",
      "candidates \n",
      " [[1.        0.        0.1736711]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         0.         0.15190745]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[0.         0.         0.15130427]]\n",
      "wrong prediction for [4 0]\n",
      "candidates \n",
      " [[1.        0.        0.1638262]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.13456183]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         1.         0.12536195]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.14758403]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         0.         0.14852329]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.12820952]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         1.         0.14017806]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.15121037]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.14610153]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[0.         1.         0.14057476]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.16564474]]\n",
      "wrong prediction for [4 2]\n",
      "candidates \n",
      " [[1.         0.         0.13253077]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[0.         0.         0.16408529]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         1.         0.19696741]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[0.         1.         0.18815354]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         0.         0.17008344]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         0.         0.15113459]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.        1.        0.1110286]]\n",
      "wrong prediction for [3 2]\n",
      "candidates \n",
      " [[1.         0.         0.13876401]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.13457551]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.12103209]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.12486993]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.13730102]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.16610726]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         0.         0.14659215]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         0.         0.16352944]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[1.         0.         0.15057726]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[0.         0.         0.17104086]]\n",
      "wrong prediction for [5 0]\n",
      "candidates \n",
      " [[2.         0.         0.12534636]]\n",
      "wrong prediction for [2 2]\n",
      "candidates \n",
      " [[0.         1.         0.11506501]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.15247717]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[0.         1.         0.20645797]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.13532596]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         0.         0.13959861]]\n",
      "wrong prediction for [1 5]\n",
      "candidates \n",
      " [[0.         1.         0.16433316]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[0.         1.         0.16532576]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.14265479]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         0.         0.12891459]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[0.         0.         0.14917055]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.15512154]]\n",
      "wrong prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.10421756]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[0.       0.       0.195166]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[0.         2.         0.14623798]]\n",
      "wrong prediction for [1 7]\n",
      "candidates \n",
      " [[1.         0.         0.13654311]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13095238095238096"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"teamA_def_mean\": teamA_def_mean,\n",
    "    \"teamA_def_std\": teamA_def_std,\n",
    "    \"teamA_off_mean\": teamA_off_mean,\n",
    "    \"teamA_off_std\": teamA_off_std,\n",
    "    \"teamB_def_mean\": teamB_def_mean,\n",
    "    \"teamB_def_std\": teamB_def_std,\n",
    "    \"teamB_off_mean\": teamB_off_mean,\n",
    "    \"teamB_off_std\": teamB_off_std,\n",
    "    \"teamA_frag_mean\": teamA_frag_mean, \n",
    "    \"teamA_frag_std\": teamA_frag_std,\n",
    "    \"teamB_frag_mean\": teamB_frag_mean, \n",
    "    \"teamB_frag_std\": teamB_frag_std,\n",
    "    \"teamA_age_mean\": teamA_age_mean, \n",
    "    \"teamA_age_std\": teamA_age_std,\n",
    "    \"teamB_age_mean\": teamB_age_mean,\n",
    "    \"teamB_age_std\": teamB_age_std,\n",
    "    \"state_dict\": neural.state_dict(),\n",
    "}\n",
    "#torch.save(state, 'model/model_r3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_pois = torch.nn.PoissonNLLLoss()\n",
    "neural_pois = PoNet(len(col),30,20,2,0.3)\n",
    "optimizer_pois = optim.RMSprop(params=neural.parameters(), lr=1e-3, alpha=0.99, eps=1e-05, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.822608470916748 0.29253731343283584 0.30952380952380953\n",
      "1 3.909024238586426 0.3074626865671642 0.30952380952380953\n",
      "2 3.7601242065429688 0.31044776119402984 0.30952380952380953\n",
      "3 3.8498096466064453 0.31044776119402984 0.30952380952380953\n",
      "4 3.886183500289917 0.2865671641791045 0.30952380952380953\n",
      "5 3.9369940757751465 0.2656716417910448 0.30952380952380953\n",
      "6 3.8860971927642822 0.3164179104477612 0.30952380952380953\n",
      "7 3.843522310256958 0.31343283582089554 0.30952380952380953\n",
      "8 3.880828619003296 0.3194029850746269 0.30952380952380953\n",
      "9 3.9333205223083496 0.3283582089552239 0.30952380952380953\n",
      "10 3.8387069702148438 0.3283582089552239 0.30952380952380953\n",
      "11 3.8445682525634766 0.32238805970149254 0.30952380952380953\n",
      "12 3.8278656005859375 0.2955223880597015 0.30952380952380953\n",
      "13 3.7638604640960693 0.3164179104477612 0.30952380952380953\n",
      "14 3.8459274768829346 0.31044776119402984 0.30952380952380953\n",
      "15 3.8478012084960938 0.28955223880597014 0.30952380952380953\n",
      "16 3.8528056144714355 0.33134328358208953 0.30952380952380953\n",
      "17 3.920158863067627 0.3164179104477612 0.30952380952380953\n",
      "18 3.7873854637145996 0.32238805970149254 0.30952380952380953\n",
      "19 3.8241186141967773 0.3253731343283582 0.30952380952380953\n",
      "20 3.859060764312744 0.3164179104477612 0.30952380952380953\n",
      "21 3.898352861404419 0.31044776119402984 0.30952380952380953\n",
      "22 3.8802590370178223 0.3074626865671642 0.30952380952380953\n",
      "23 3.808049201965332 0.2835820895522388 0.30952380952380953\n",
      "24 3.868276357650757 0.3253731343283582 0.30952380952380953\n",
      "25 3.811765193939209 0.3492537313432836 0.30952380952380953\n",
      "26 3.832514762878418 0.32238805970149254 0.30952380952380953\n",
      "27 3.883254289627075 0.3283582089552239 0.30952380952380953\n",
      "28 3.816680669784546 0.3164179104477612 0.30952380952380953\n",
      "29 3.919567584991455 0.27761194029850744 0.30952380952380953\n",
      "30 3.7846574783325195 0.31044776119402984 0.30952380952380953\n",
      "31 3.8616557121276855 0.31343283582089554 0.30952380952380953\n",
      "32 3.8332247734069824 0.3373134328358209 0.30952380952380953\n",
      "33 3.804490089416504 0.25671641791044775 0.30952380952380953\n",
      "34 3.9445815086364746 0.33432835820895523 0.30952380952380953\n",
      "35 3.893688678741455 0.3253731343283582 0.30952380952380953\n",
      "36 3.8135128021240234 0.3253731343283582 0.30952380952380953\n",
      "37 3.942575693130493 0.2865671641791045 0.30952380952380953\n",
      "38 3.9137511253356934 0.3044776119402985 0.30952380952380953\n",
      "39 3.800271987915039 0.3253731343283582 0.30952380952380953\n",
      "40 3.7659473419189453 0.2955223880597015 0.30952380952380953\n",
      "41 3.889127492904663 0.3402985074626866 0.30952380952380953\n",
      "42 3.889294385910034 0.2955223880597015 0.30952380952380953\n",
      "43 3.9104597568511963 0.3194029850746269 0.30952380952380953\n",
      "44 3.8504698276519775 0.33432835820895523 0.30952380952380953\n",
      "45 3.8054115772247314 0.2955223880597015 0.30952380952380953\n",
      "46 3.8531312942504883 0.3402985074626866 0.30952380952380953\n",
      "47 3.966937780380249 0.3074626865671642 0.30952380952380953\n",
      "48 3.8170454502105713 0.2955223880597015 0.30952380952380953\n",
      "49 3.814708709716797 0.27761194029850744 0.30952380952380953\n",
      "50 3.8359498977661133 0.3044776119402985 0.30952380952380953\n",
      "51 3.8874943256378174 0.30149253731343284 0.30952380952380953\n",
      "52 3.8815295696258545 0.3283582089552239 0.30952380952380953\n",
      "53 3.899186372756958 0.33432835820895523 0.30952380952380953\n",
      "54 3.9006333351135254 0.32238805970149254 0.30952380952380953\n",
      "55 3.8162434101104736 0.31343283582089554 0.30952380952380953\n",
      "56 3.903249502182007 0.29253731343283584 0.30952380952380953\n",
      "57 3.8890819549560547 0.31044776119402984 0.30952380952380953\n",
      "58 3.768437385559082 0.31044776119402984 0.30952380952380953\n",
      "59 3.892711639404297 0.3253731343283582 0.30952380952380953\n",
      "60 3.8875622749328613 0.2835820895522388 0.30952380952380953\n",
      "61 3.860055923461914 0.2865671641791045 0.30952380952380953\n",
      "62 3.8789429664611816 0.26865671641791045 0.30952380952380953\n",
      "63 3.9101009368896484 0.3492537313432836 0.30952380952380953\n",
      "64 3.8955612182617188 0.26865671641791045 0.30952380952380953\n",
      "65 3.944377899169922 0.31343283582089554 0.30952380952380953\n",
      "66 3.8638691902160645 0.3044776119402985 0.30952380952380953\n",
      "67 3.8601722717285156 0.28955223880597014 0.30952380952380953\n",
      "68 3.8671138286590576 0.3373134328358209 0.30952380952380953\n",
      "69 3.8595213890075684 0.31044776119402984 0.30952380952380953\n",
      "70 3.8502652645111084 0.3194029850746269 0.30952380952380953\n",
      "71 3.829235076904297 0.3164179104477612 0.30952380952380953\n",
      "72 3.8660073280334473 0.29253731343283584 0.30952380952380953\n",
      "73 3.806520938873291 0.32238805970149254 0.30952380952380953\n",
      "74 3.831268787384033 0.32238805970149254 0.30952380952380953\n",
      "75 3.8266451358795166 0.29850746268656714 0.30952380952380953\n",
      "76 3.797175407409668 0.31343283582089554 0.30952380952380953\n",
      "77 3.7397336959838867 0.37910447761194027 0.30952380952380953\n",
      "78 3.8429219722747803 0.2656716417910448 0.30952380952380953\n",
      "79 3.919639825820923 0.27761194029850744 0.30952380952380953\n",
      "80 3.82999324798584 0.3044776119402985 0.30952380952380953\n",
      "81 3.8740758895874023 0.31343283582089554 0.30952380952380953\n",
      "82 3.8614792823791504 0.30149253731343284 0.30952380952380953\n",
      "83 3.938044786453247 0.32238805970149254 0.30952380952380953\n",
      "84 3.821345329284668 0.3283582089552239 0.30952380952380953\n",
      "85 3.893085479736328 0.3164179104477612 0.30952380952380953\n",
      "86 3.8013744354248047 0.33432835820895523 0.30952380952380953\n",
      "87 4.140232086181641 0.3044776119402985 0.30952380952380953\n",
      "88 3.892904758453369 0.3074626865671642 0.30952380952380953\n",
      "89 3.8894782066345215 0.27761194029850744 0.30952380952380953\n",
      "90 3.8395838737487793 0.31343283582089554 0.30952380952380953\n",
      "91 3.8134679794311523 0.3074626865671642 0.30952380952380953\n",
      "92 3.8204383850097656 0.34626865671641793 0.30952380952380953\n",
      "93 3.8598923683166504 0.3164179104477612 0.30952380952380953\n",
      "94 3.8151192665100098 0.3074626865671642 0.30952380952380953\n",
      "95 3.8051462173461914 0.2656716417910448 0.30952380952380953\n",
      "96 3.8845038414001465 0.31044776119402984 0.30952380952380953\n",
      "97 3.7779369354248047 0.3402985074626866 0.30952380952380953\n",
      "98 3.873647689819336 0.2955223880597015 0.30952380952380953\n",
      "99 3.8372538089752197 0.30149253731343284 0.30952380952380953\n",
      "100 3.8687450885772705 0.3164179104477612 0.30952380952380953\n",
      "101 3.828873634338379 0.31343283582089554 0.30952380952380953\n",
      "102 3.894812822341919 0.31044776119402984 0.30952380952380953\n",
      "103 4.041108131408691 0.3044776119402985 0.30952380952380953\n",
      "104 3.8696494102478027 0.31343283582089554 0.30952380952380953\n",
      "105 3.8693690299987793 0.3283582089552239 0.30952380952380953\n",
      "106 3.8224129676818848 0.3074626865671642 0.30952380952380953\n",
      "107 3.854165554046631 0.3044776119402985 0.30952380952380953\n",
      "108 3.8517041206359863 0.28955223880597014 0.30952380952380953\n",
      "109 3.8390004634857178 0.3194029850746269 0.30952380952380953\n",
      "110 3.947713613510132 0.3194029850746269 0.30952380952380953\n",
      "111 3.8574609756469727 0.3074626865671642 0.30952380952380953\n",
      "112 3.8615646362304688 0.32238805970149254 0.30952380952380953\n",
      "113 3.8158178329467773 0.3522388059701492 0.30952380952380953\n",
      "114 3.8573498725891113 0.31343283582089554 0.30952380952380953\n",
      "115 3.8360443115234375 0.2955223880597015 0.30952380952380953\n",
      "116 3.8736636638641357 0.2865671641791045 0.30952380952380953\n",
      "117 3.8517346382141113 0.3044776119402985 0.30952380952380953\n",
      "118 3.835948944091797 0.30149253731343284 0.30952380952380953\n",
      "119 3.782459020614624 0.33134328358208953 0.30952380952380953\n",
      "120 3.8494555950164795 0.32238805970149254 0.30952380952380953\n",
      "121 3.923707962036133 0.2626865671641791 0.30952380952380953\n",
      "122 3.908092498779297 0.2716417910447761 0.30952380952380953\n",
      "123 3.855865001678467 0.3611940298507463 0.30952380952380953\n",
      "124 3.810427665710449 0.31044776119402984 0.30952380952380953\n",
      "125 3.818650245666504 0.33134328358208953 0.30952380952380953\n",
      "126 3.877485513687134 0.2955223880597015 0.30952380952380953\n",
      "127 3.8616855144500732 0.30149253731343284 0.30952380952380953\n",
      "128 3.8354077339172363 0.2835820895522388 0.30952380952380953\n",
      "129 3.8455564975738525 0.32238805970149254 0.30952380952380953\n",
      "130 3.924264907836914 0.3164179104477612 0.30952380952380953\n",
      "131 3.878159523010254 0.3402985074626866 0.30952380952380953\n",
      "132 3.8156895637512207 0.29253731343283584 0.30952380952380953\n",
      "133 3.769833564758301 0.3253731343283582 0.30952380952380953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 3.7900476455688477 0.3074626865671642 0.30952380952380953\n",
      "135 3.901623249053955 0.29850746268656714 0.30952380952380953\n",
      "136 3.9296488761901855 0.31044776119402984 0.30952380952380953\n",
      "137 3.9260127544403076 0.3194029850746269 0.30952380952380953\n",
      "138 3.815800666809082 0.3373134328358209 0.30952380952380953\n",
      "139 3.821709156036377 0.33134328358208953 0.30952380952380953\n",
      "140 3.810063362121582 0.29253731343283584 0.30952380952380953\n",
      "141 3.8914575576782227 0.3164179104477612 0.30952380952380953\n",
      "142 3.8823795318603516 0.28955223880597014 0.30952380952380953\n",
      "143 3.8600616455078125 0.28955223880597014 0.30952380952380953\n",
      "144 3.8364827632904053 0.31343283582089554 0.30952380952380953\n",
      "145 3.916614294052124 0.29850746268656714 0.30952380952380953\n",
      "146 3.7954201698303223 0.29850746268656714 0.30952380952380953\n",
      "147 3.9195587635040283 0.2835820895522388 0.30952380952380953\n",
      "148 3.812534809112549 0.2955223880597015 0.30952380952380953\n",
      "149 3.9058456420898438 0.33432835820895523 0.30952380952380953\n",
      "150 3.8472728729248047 0.31343283582089554 0.30952380952380953\n",
      "151 3.7979745864868164 0.34328358208955223 0.30952380952380953\n",
      "152 3.795252799987793 0.31044776119402984 0.30952380952380953\n",
      "153 3.8101961612701416 0.31343283582089554 0.30952380952380953\n",
      "154 3.8912272453308105 0.3402985074626866 0.30952380952380953\n",
      "155 4.016824722290039 0.2865671641791045 0.30952380952380953\n",
      "156 3.8139829635620117 0.3373134328358209 0.30952380952380953\n",
      "157 3.7749409675598145 0.2716417910447761 0.30952380952380953\n",
      "158 3.7992262840270996 0.3253731343283582 0.30952380952380953\n",
      "159 3.846534252166748 0.29850746268656714 0.30952380952380953\n",
      "160 3.8616533279418945 0.3044776119402985 0.30952380952380953\n",
      "161 3.870372772216797 0.29850746268656714 0.30952380952380953\n",
      "162 3.8587870597839355 0.29253731343283584 0.30952380952380953\n",
      "163 3.8812167644500732 0.2955223880597015 0.30952380952380953\n",
      "164 3.799190044403076 0.3074626865671642 0.30952380952380953\n",
      "165 3.7984631061553955 0.31044776119402984 0.30952380952380953\n",
      "166 3.9868249893188477 0.3402985074626866 0.30952380952380953\n",
      "167 3.8402419090270996 0.28955223880597014 0.30952380952380953\n",
      "168 3.9245309829711914 0.34328358208955223 0.30952380952380953\n",
      "169 3.9748010635375977 0.28059701492537314 0.30952380952380953\n",
      "170 3.9032607078552246 0.3253731343283582 0.30952380952380953\n",
      "171 3.96429705619812 0.32238805970149254 0.30952380952380953\n",
      "172 3.8728280067443848 0.32238805970149254 0.30952380952380953\n",
      "173 3.7550854682922363 0.32238805970149254 0.30952380952380953\n",
      "174 3.777188301086426 0.3373134328358209 0.30952380952380953\n",
      "175 3.822082042694092 0.33432835820895523 0.30952380952380953\n",
      "176 3.8892979621887207 0.31044776119402984 0.30952380952380953\n",
      "177 3.853149890899658 0.31343283582089554 0.30952380952380953\n",
      "178 3.819796562194824 0.32238805970149254 0.30952380952380953\n",
      "179 3.8209898471832275 0.3253731343283582 0.30952380952380953\n",
      "180 3.858048915863037 0.32238805970149254 0.30952380952380953\n",
      "181 3.8524951934814453 0.3402985074626866 0.30952380952380953\n",
      "182 3.8859920501708984 0.2955223880597015 0.30952380952380953\n",
      "183 3.996041774749756 0.3074626865671642 0.30952380952380953\n",
      "184 3.8924007415771484 0.2955223880597015 0.30952380952380953\n",
      "185 3.894331693649292 0.3373134328358209 0.30952380952380953\n",
      "186 3.870223045349121 0.28955223880597014 0.30952380952380953\n",
      "187 3.8974103927612305 0.3283582089552239 0.30952380952380953\n",
      "188 3.93721342086792 0.3074626865671642 0.30952380952380953\n",
      "189 3.813119649887085 0.35522388059701493 0.30952380952380953\n",
      "190 3.85673451423645 0.3074626865671642 0.30952380952380953\n",
      "191 3.8394479751586914 0.34626865671641793 0.30952380952380953\n",
      "192 3.8256726264953613 0.3164179104477612 0.30952380952380953\n",
      "193 3.858919143676758 0.30149253731343284 0.30952380952380953\n",
      "194 3.8133769035339355 0.3253731343283582 0.30952380952380953\n",
      "195 3.7906653881073 0.3283582089552239 0.30952380952380953\n",
      "196 3.7928247451782227 0.3283582089552239 0.30952380952380953\n",
      "197 3.8308300971984863 0.32238805970149254 0.30952380952380953\n",
      "198 3.830270767211914 0.29850746268656714 0.30952380952380953\n",
      "199 3.8442559242248535 0.33432835820895523 0.30952380952380953\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # train\n",
    "    neural_pois.train()\n",
    "    mu = neural_pois(X_tr)\n",
    "    lossA_pois = crit_pois(mu[:,[0]],y_trA)\n",
    "    lossB_pois = crit_pois(mu[:,[1]],y_trB)\n",
    "    loss_pois = lossA_pois+lossB_pois    \n",
    "    tend_acc_tr = util.tend_acc_pois(mu.data.numpy(),y_train)\n",
    "    # evaluate\n",
    "    neural_pois.eval()\n",
    "    mu = neural_pois(X_te)\n",
    "    tend_acc_val = util.tend_acc_pois(mu.data.numpy(),y_test)\n",
    "    print(epoch, loss_pois.item(),tend_acc_tr,tend_acc_val)\n",
    "    # update\n",
    "    optimizer_pois.zero_grad()\n",
    "    loss_pois.backward()\n",
    "    optimizer_pois.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pois.eval()\n",
    "mu=neural_pois(X_te).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13505781]\n",
      " [1.         0.         0.13061192]\n",
      " [0.         1.         0.12795515]\n",
      " [0.         0.         0.12374307]\n",
      " [2.         1.         0.07127736]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[1.         1.         0.13296953]\n",
      " [0.         1.         0.12389869]\n",
      " [1.         0.         0.11231888]\n",
      " [0.         0.         0.10465677]\n",
      " [1.         2.         0.07870848]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13043708]\n",
      " [0.         1.         0.11559934]\n",
      " [1.         0.         0.10337009]\n",
      " [0.         0.         0.09161133]\n",
      " [1.         2.         0.08229572]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         1.         0.13254125]\n",
      " [1.         0.         0.11695304]\n",
      " [0.         1.         0.11348409]\n",
      " [0.         0.         0.10013721]\n",
      " [2.         1.         0.07739932]]\n",
      "wrong prediction for [2 2]\n",
      "candidates \n",
      " [[1.         1.         0.13331675]\n",
      " [0.         1.         0.12227116]\n",
      " [1.         0.         0.11522063]\n",
      " [0.         0.         0.10567433]\n",
      " [1.         2.         0.0771275 ]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13391271]\n",
      " [0.         1.         0.12404635]\n",
      " [1.         0.         0.11870907]\n",
      " [0.         0.         0.10996288]\n",
      " [1.         2.         0.07553177]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.13227527]\n",
      " [0.         1.         0.12200187]\n",
      " [1.         0.         0.10924966]\n",
      " [0.         0.         0.10076458]\n",
      " [1.         2.         0.0800769 ]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13498586]\n",
      " [0.         1.         0.1287802 ]\n",
      " [1.         0.         0.12794637]\n",
      " [0.         0.         0.12206434]\n",
      " [1.         2.         0.07120632]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.1271245 ]\n",
      " [0.         1.         0.11308672]\n",
      " [1.         0.         0.09272197]\n",
      " [1.         2.         0.08714568]\n",
      " [0.         0.         0.08248311]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13480437]\n",
      " [0.         1.         0.13095492]\n",
      " [1.         0.         0.1241175 ]\n",
      " [0.         0.         0.12057322]\n",
      " [1.         2.         0.0732057 ]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[1.         1.         0.1187854 ]\n",
      " [0.         1.         0.10555337]\n",
      " [1.         2.         0.09393822]\n",
      " [0.         2.         0.08347403]\n",
      " [1.         0.         0.07510239]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13215407]\n",
      " [0.         1.         0.11599262]\n",
      " [1.         0.         0.11174115]\n",
      " [0.         0.         0.09807605]\n",
      " [1.         2.         0.07814801]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13344135]\n",
      " [0.         1.         0.12192193]\n",
      " [1.         0.         0.11630607]\n",
      " [0.         0.         0.10626587]\n",
      " [1.         2.         0.07655058]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.12416812]\n",
      " [0.         1.         0.11227406]\n",
      " [1.         2.         0.09050677]\n",
      " [1.         0.         0.08517442]\n",
      " [0.         2.         0.08183713]]\n",
      "wrong prediction for [6 1]\n",
      "candidates \n",
      " [[1.         1.         0.13432159]\n",
      " [0.         1.         0.12561395]\n",
      " [1.         0.         0.12148114]\n",
      " [0.         0.         0.1136059 ]\n",
      " [1.         2.         0.07425964]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13384005]\n",
      " [0.         1.         0.1222282 ]\n",
      " [1.         0.         0.11930962]\n",
      " [0.         0.         0.10895843]\n",
      " [1.         2.         0.07507005]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.1325254 ]\n",
      " [0.         1.         0.12022906]\n",
      " [1.         0.         0.11134505]\n",
      " [0.         0.         0.10101392]\n",
      " [1.         2.         0.07886736]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13234572]\n",
      " [0.         1.         0.11895992]\n",
      " [1.         0.         0.11098345]\n",
      " [0.         0.         0.09975829]\n",
      " [1.         2.         0.07890991]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.13167533]\n",
      " [0.         1.         0.12211269]\n",
      " [1.         0.         0.10636216]\n",
      " [0.         0.         0.09863783]\n",
      " [1.         2.         0.0815064 ]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.13416653]\n",
      " [1.         0.         0.12490289]\n",
      " [0.         1.         0.12042713]\n",
      " [0.         0.         0.11211214]\n",
      " [2.         1.         0.07473672]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.12077587]\n",
      " [0.         1.         0.0888396 ]\n",
      " [1.         0.         0.08672404]\n",
      " [1.         2.         0.084099  ]\n",
      " [2.         1.         0.08209633]]\n",
      "wrong prediction for [1 3]\n",
      "candidates \n",
      " [[1.         1.         0.12994593]\n",
      " [0.         1.         0.11222416]\n",
      " [1.         0.         0.10295224]\n",
      " [0.         0.         0.08891182]\n",
      " [1.         2.         0.08200863]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         1.         0.13426882]\n",
      " [0.         1.         0.12727867]\n",
      " [1.         0.         0.12009973]\n",
      " [0.         0.         0.11384723]\n",
      " [1.         2.         0.07505478]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.12965751]\n",
      " [0.         1.         0.11142306]\n",
      " [1.         0.         0.10217312]\n",
      " [0.         0.         0.08780396]\n",
      " [1.         2.         0.08226757]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.13062007]\n",
      " [0.         1.         0.11303639]\n",
      " [1.         0.         0.1055156 ]\n",
      " [0.         0.         0.09131142]\n",
      " [1.         2.         0.08084872]]\n",
      "wrong prediction for [4 1]\n",
      "candidates \n",
      " [[1.         1.         0.1332236 ]\n",
      " [0.         1.         0.11962903]\n",
      " [1.         0.         0.11625258]\n",
      " [0.         0.         0.10438979]\n",
      " [1.         2.         0.07633606]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.1260047 ]\n",
      " [0.         1.         0.11768605]\n",
      " [1.         2.         0.08940078]\n",
      " [1.         0.         0.0887978 ]\n",
      " [0.         2.         0.08349866]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13425439]\n",
      " [1.         0.         0.12645509]\n",
      " [0.         1.         0.12035941]\n",
      " [0.         0.         0.11336732]\n",
      " [2.         1.         0.07487674]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         0.         0.13649061]\n",
      " [1.         1.         0.13519572]\n",
      " [0.         0.         0.13060318]\n",
      " [0.         1.         0.12936414]\n",
      " [2.         0.         0.07132172]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.13507988]\n",
      " [1.         0.         0.1320246 ]\n",
      " [0.         1.         0.12766239]\n",
      " [0.         0.         0.12477488]\n",
      " [2.         1.         0.07146417]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13053586]\n",
      " [0.         1.         0.11187273]\n",
      " [1.         0.         0.10585986]\n",
      " [0.         0.         0.09072475]\n",
      " [1.         2.         0.08048192]]\n",
      "wrong prediction for [0 3]\n",
      "candidates \n",
      " [[1.         1.         0.13418274]\n",
      " [0.         1.         0.12720236]\n",
      " [1.         0.         0.11938581]\n",
      " [0.         0.         0.11317519]\n",
      " [1.         2.         0.07540682]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.1342365 ]\n",
      " [0.         1.         0.12797385]\n",
      " [1.         0.         0.11953765]\n",
      " [0.         0.         0.11396076]\n",
      " [1.         2.         0.07537139]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.132002  ]\n",
      " [0.         1.         0.11868157]\n",
      " [1.         0.         0.10925183]\n",
      " [0.         0.         0.09822714]\n",
      " [1.         2.         0.07974478]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13422105]\n",
      " [1.         0.         0.12405345]\n",
      " [0.         1.         0.12155219]\n",
      " [0.         0.         0.1123443 ]\n",
      " [2.         1.         0.07410516]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13236709]\n",
      " [0.         1.         0.11497637]\n",
      " [1.         0.         0.11397192]\n",
      " [0.         0.         0.09899801]\n",
      " [1.         2.         0.07686563]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.13713716]\n",
      " [1.         1.         0.13514865]\n",
      " [0.         0.         0.1304419 ]\n",
      " [0.         1.         0.12855046]\n",
      " [2.         0.         0.07208804]]\n",
      "wrong prediction for [1 5]\n",
      "candidates \n",
      " [[1.         1.         0.1120941 ]\n",
      " [0.         1.         0.10250154]\n",
      " [1.         2.         0.09728135]\n",
      " [0.         2.         0.08895641]\n",
      " [1.         0.         0.06458117]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.12888393]\n",
      " [0.         1.         0.11620121]\n",
      " [1.         0.         0.09736089]\n",
      " [0.         0.         0.08778017]\n",
      " [1.         2.         0.08530667]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.13125609]\n",
      " [1.         0.         0.11089646]\n",
      " [0.         1.         0.11058035]\n",
      " [0.         0.         0.09342781]\n",
      " [2.         1.         0.07789884]]\n",
      "wrong prediction for [4 0]\n",
      "candidates \n",
      " [[1.         1.         0.13447176]\n",
      " [1.         0.         0.12953194]\n",
      " [0.         1.         0.1210887 ]\n",
      " [0.         0.         0.11664051]\n",
      " [2.         1.         0.07466697]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.12659277]\n",
      " [0.         1.         0.10659013]\n",
      " [1.         0.         0.09345104]\n",
      " [1.         2.         0.08574399]\n",
      " [0.         0.         0.07868505]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13187693]\n",
      " [1.         0.         0.11300621]\n",
      " [0.         1.         0.11249954]\n",
      " [0.         0.         0.09640159]\n",
      " [2.         1.         0.07729598]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13453726]\n",
      " [0.         1.         0.12646609]\n",
      " [1.         0.         0.12324135]\n",
      " [0.         0.         0.11584784]\n",
      " [1.         2.         0.07343426]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13521513]\n",
      " [0.         1.         0.13195657]\n",
      " [1.         0.         0.13068143]\n",
      " [0.         0.         0.12753213]\n",
      " [1.         2.         0.06995306]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13039608]\n",
      " [0.         1.         0.11269067]\n",
      " [1.         0.         0.10468072]\n",
      " [0.         0.         0.09046699]\n",
      " [1.         2.         0.08121427]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13331185]\n",
      " [0.         1.         0.12732731]\n",
      " [1.         0.         0.11328851]\n",
      " [0.         0.         0.10820285]\n",
      " [1.         2.         0.07843712]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13346321]\n",
      " [0.         1.         0.12510985]\n",
      " [1.         0.         0.11490079]\n",
      " [0.         0.         0.10770924]\n",
      " [1.         2.         0.07751221]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13498636]\n",
      " [1.         0.         0.13005895]\n",
      " [0.         1.         0.12703363]\n",
      " [0.         0.         0.12239652]\n",
      " [2.         1.         0.07171848]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.13279108]\n",
      " [0.         1.         0.12331607]\n",
      " [1.         0.         0.11151728]\n",
      " [0.         0.         0.10356021]\n",
      " [1.         2.         0.07906162]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.13743834]\n",
      " [1.         1.         0.13524199]\n",
      " [0.         0.         0.13293755]\n",
      " [0.         1.         0.13081313]\n",
      " [2.         0.         0.07104575]]\n",
      "wrong prediction for [4 2]\n",
      "candidates \n",
      " [[1.         1.         0.13320746]\n",
      " [0.         1.         0.12818986]\n",
      " [1.         0.         0.11250668]\n",
      " [0.         0.         0.10826882]\n",
      " [1.         2.         0.07885856]]\n",
      "right prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.13492362]\n",
      " [0.         1.         0.12876351]\n",
      " [1.         0.         0.12686215]\n",
      " [0.         0.         0.1210701 ]\n",
      " [1.         2.         0.07174868]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         0.         0.14025646]\n",
      " [1.         1.         0.13509991]\n",
      " [0.         0.         0.13402694]\n",
      " [0.         1.         0.12909942]\n",
      " [2.         0.         0.07338776]]\n",
      "right prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.13401848]\n",
      " [0.         1.         0.12272983]\n",
      " [1.         0.         0.12057373]\n",
      " [0.         0.         0.11041756]\n",
      " [1.         2.         0.0744812 ]]\n",
      "wrong prediction for [3 1]\n",
      "candidates \n",
      " [[1.         1.         0.13103417]\n",
      " [0.         1.         0.12472763]\n",
      " [1.         0.         0.103147  ]\n",
      " [0.         0.         0.09818264]\n",
      " [1.         2.         0.0832305 ]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13318545]\n",
      " [0.         1.         0.12226282]\n",
      " [1.         0.         0.11434582]\n",
      " [0.         0.         0.10496824]\n",
      " [1.         2.         0.07756455]]\n",
      "right prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.13376047]\n",
      " [0.         1.         0.12124726]\n",
      " [1.         0.         0.1193814 ]\n",
      " [0.         0.         0.10821333]\n",
      " [1.         2.         0.07493573]]\n",
      "wrong prediction for [3 2]\n",
      "candidates \n",
      " [[1.         1.         0.13330524]\n",
      " [1.         0.         0.12268693]\n",
      " [0.         1.         0.11492446]\n",
      " [0.         0.         0.10577025]\n",
      " [2.         1.         0.07731291]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13254333]\n",
      " [0.         1.         0.12334037]\n",
      " [1.         0.         0.11017103]\n",
      " [0.         0.         0.10252146]\n",
      " [1.         2.         0.07972938]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.13283645]\n",
      " [0.         1.         0.1175229 ]\n",
      " [1.         0.         0.11506958]\n",
      " [0.         0.         0.10180422]\n",
      " [1.         2.         0.07667327]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13081889]\n",
      " [0.         1.         0.11553503]\n",
      " [1.         0.         0.10506282]\n",
      " [0.         0.         0.0927881 ]\n",
      " [1.         2.         0.08144452]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.13532311]\n",
      " [0.         1.         0.13414064]\n",
      " [1.         0.         0.13396162]\n",
      " [0.         0.         0.13279104]\n",
      " [1.         2.         0.06834922]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13458587]\n",
      " [0.         1.         0.13159643]\n",
      " [1.         0.         0.12163145]\n",
      " [0.         0.         0.11892975]\n",
      " [1.         2.         0.07446   ]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13309576]\n",
      " [0.         1.         0.12414868]\n",
      " [1.         0.         0.11296801]\n",
      " [0.         0.         0.10537397]\n",
      " [1.         2.         0.07840486]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13444215]\n",
      " [0.         1.         0.12427567]\n",
      " [1.         0.         0.12387027]\n",
      " [0.         0.         0.11450324]\n",
      " [1.         2.         0.07295815]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.13476312]\n",
      " [0.         1.         0.13040845]\n",
      " [1.         0.         0.12381766]\n",
      " [0.         0.         0.11981667]\n",
      " [1.         2.         0.07333808]]\n",
      "wrong prediction for [0 2]\n",
      "candidates \n",
      " [[1.         1.         0.13103591]\n",
      " [0.         1.         0.12076299]\n",
      " [1.         0.         0.10400862]\n",
      " [0.         0.         0.09585458]\n",
      " [1.         2.         0.0825432 ]]\n",
      "wrong prediction for [5 0]\n",
      "candidates \n",
      " [[1.         1.         0.13280369]\n",
      " [0.         1.         0.11665778]\n",
      " [1.         0.         0.11558311]\n",
      " [0.         0.         0.10153083]\n",
      " [1.         2.         0.07629497]]\n",
      "wrong prediction for [2 2]\n",
      "candidates \n",
      " [[1.         1.         0.13130126]\n",
      " [0.         1.         0.11246743]\n",
      " [1.         0.         0.10944354]\n",
      " [0.         0.         0.09374497]\n",
      " [1.         2.         0.07876217]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13133488]\n",
      " [0.         1.         0.127891  ]\n",
      " [1.         0.         0.10393177]\n",
      " [0.         0.         0.10120645]\n",
      " [1.         2.         0.08298161]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.13106491]\n",
      " [0.         1.         0.11902807]\n",
      " [1.         0.         0.10467939]\n",
      " [0.         0.         0.09506576]\n",
      " [1.         2.         0.08205059]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.13321586]\n",
      " [0.         1.         0.11830323]\n",
      " [1.         0.         0.11729922]\n",
      " [0.         0.         0.10416836]\n",
      " [1.         2.         0.07564613]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.134524  ]\n",
      " [1.         0.         0.12682235]\n",
      " [0.         1.         0.12286008]\n",
      " [0.         0.         0.11582621]\n",
      " [2.         1.         0.07364763]]\n",
      "wrong prediction for [1 5]\n",
      "candidates \n",
      " [[1.         1.         0.13488371]\n",
      " [1.         0.         0.12965825]\n",
      " [0.         1.         0.12569024]\n",
      " [0.         0.         0.12082094]\n",
      " [2.         1.         0.07237481]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.12972835]\n",
      " [0.         1.         0.11435353]\n",
      " [1.         0.         0.1010378 ]\n",
      " [0.         0.         0.08906326]\n",
      " [1.         2.         0.08328291]]\n",
      "right prediction for [1 1]\n",
      "candidates \n",
      " [[1.         1.         0.1336475 ]\n",
      " [1.         0.         0.12174039]\n",
      " [0.         1.         0.11802472]\n",
      " [0.         0.         0.1075095 ]\n",
      " [2.         1.         0.07566912]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.         1.         0.13238588]\n",
      " [0.         1.         0.11950917]\n",
      " [1.         0.         0.11091911]\n",
      " [0.         0.         0.1001304 ]\n",
      " [1.         2.         0.07900361]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.13313582]\n",
      " [0.         1.         0.12378009]\n",
      " [1.         0.         0.11335024]\n",
      " [0.         0.         0.10538489]\n",
      " [1.         2.         0.07818751]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         1.         0.12307353]\n",
      " [0.         1.         0.10394003]\n",
      " [1.         2.         0.08950941]\n",
      " [1.         0.         0.08461174]\n",
      " [0.         2.         0.07559392]]\n",
      "right prediction for [0 0]\n",
      "candidates \n",
      " [[1.         1.         0.13198301]\n",
      " [0.         1.         0.12564791]\n",
      " [1.         0.         0.10690383]\n",
      " [0.         0.         0.10177251]\n",
      " [1.         2.         0.08147284]]\n",
      "right prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.13392963]\n",
      " [0.         1.         0.12268365]\n",
      " [1.         0.         0.11977256]\n",
      " [0.         0.         0.10971534]\n",
      " [1.         2.         0.07488003]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[1.         1.         0.13452394]\n",
      " [0.         1.         0.12621048]\n",
      " [1.         0.         0.12326382]\n",
      " [0.         0.         0.11564623]\n",
      " [1.         2.         0.07340633]]\n",
      "wrong prediction for [1 7]\n",
      "candidates \n",
      " [[1.         0.         0.13613452]\n",
      " [1.         1.         0.13515878]\n",
      " [0.         0.         0.12947468]\n",
      " [0.         1.         0.12854668]\n",
      " [2.         0.         0.07156846]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5357142857142857"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs=util.calc_pois_probs(mu[:,0],mu[:,1])\n",
    "util.multi_result(y=y_test,y_prob=probs,top_n=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/docs/master/notes/serialization.html#best-practices\n",
    "#https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Spieltag\n",
    "neural_pickled = NBNet(len(col),20,20,4,0.2)\n",
    "state = torch.load('model/model_r1.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>tournament</th>\n",
       "      <th>gametype</th>\n",
       "      <th>teamA</th>\n",
       "      <th>teamidA</th>\n",
       "      <th>teamB</th>\n",
       "      <th>teamidB</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>addinfo</th>\n",
       "      <th>...</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2977683</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Russland</td>\n",
       "      <td>3448</td>\n",
       "      <td>Saudi-Arabien</td>\n",
       "      <td>3807</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.420402</td>\n",
       "      <td>1.341508</td>\n",
       "      <td>0.112267</td>\n",
       "      <td>-0.636883</td>\n",
       "      <td>0.505582</td>\n",
       "      <td>-0.708195</td>\n",
       "      <td>-1.221270</td>\n",
       "      <td>-1.887689</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2977684</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Ägypten</td>\n",
       "      <td>3672</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.557573</td>\n",
       "      <td>1.001132</td>\n",
       "      <td>-0.333798</td>\n",
       "      <td>1.596695</td>\n",
       "      <td>1.250698</td>\n",
       "      <td>1.949058</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2977690</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>3300</td>\n",
       "      <td>Spanien</td>\n",
       "      <td>3375</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.137992</td>\n",
       "      <td>1.238603</td>\n",
       "      <td>1.889089</td>\n",
       "      <td>7.625774</td>\n",
       "      <td>3.335494</td>\n",
       "      <td>5.612593</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>-0.594133</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2977689</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Marokko</td>\n",
       "      <td>3575</td>\n",
       "      <td>Iran</td>\n",
       "      <td>3582</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226210</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>-0.134185</td>\n",
       "      <td>-0.581801</td>\n",
       "      <td>0.281588</td>\n",
       "      <td>-0.397746</td>\n",
       "      <td>1.385453</td>\n",
       "      <td>0.483830</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2977696</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Peru</td>\n",
       "      <td>3584</td>\n",
       "      <td>Dänemark</td>\n",
       "      <td>3436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371449</td>\n",
       "      <td>0.241222</td>\n",
       "      <td>-0.663423</td>\n",
       "      <td>0.811036</td>\n",
       "      <td>-0.461386</td>\n",
       "      <td>1.143794</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2977695</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>3377</td>\n",
       "      <td>Australien</td>\n",
       "      <td>3433</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750123</td>\n",
       "      <td>0.929890</td>\n",
       "      <td>6.658797</td>\n",
       "      <td>-0.427231</td>\n",
       "      <td>7.173991</td>\n",
       "      <td>-0.480413</td>\n",
       "      <td>-0.135135</td>\n",
       "      <td>1.346201</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2977702</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Kroatien</td>\n",
       "      <td>3556</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>3444</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750686</td>\n",
       "      <td>-0.795737</td>\n",
       "      <td>1.064370</td>\n",
       "      <td>0.056974</td>\n",
       "      <td>2.314670</td>\n",
       "      <td>0.188658</td>\n",
       "      <td>1.168226</td>\n",
       "      <td>1.130608</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2977701</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Argentinien</td>\n",
       "      <td>3437</td>\n",
       "      <td>Island</td>\n",
       "      <td>3574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090118</td>\n",
       "      <td>1.373171</td>\n",
       "      <td>1.195695</td>\n",
       "      <td>-0.574970</td>\n",
       "      <td>6.323304</td>\n",
       "      <td>-0.070645</td>\n",
       "      <td>0.516545</td>\n",
       "      <td>1.130608</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2977708</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Brasilien</td>\n",
       "      <td>3439</td>\n",
       "      <td>Schweiz</td>\n",
       "      <td>3384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315507</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>5.476876</td>\n",
       "      <td>1.717959</td>\n",
       "      <td>6.782308</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>-0.352362</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2977707</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>8497</td>\n",
       "      <td>Serbien</td>\n",
       "      <td>3438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.299909</td>\n",
       "      <td>-0.138732</td>\n",
       "      <td>-0.328545</td>\n",
       "      <td>0.929738</td>\n",
       "      <td>-0.675588</td>\n",
       "      <td>1.229435</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>1.346201</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2977713</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>3262</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>6303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161659</td>\n",
       "      <td>1.856030</td>\n",
       "      <td>6.369883</td>\n",
       "      <td>-0.340126</td>\n",
       "      <td>4.958532</td>\n",
       "      <td>0.700125</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>0.483830</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2977714</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Schweden</td>\n",
       "      <td>3557</td>\n",
       "      <td>Südkorea</td>\n",
       "      <td>3589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000821</td>\n",
       "      <td>0.684503</td>\n",
       "      <td>0.237026</td>\n",
       "      <td>-0.525439</td>\n",
       "      <td>-0.096631</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2977720</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>Tunesien</td>\n",
       "      <td>3670</td>\n",
       "      <td>England</td>\n",
       "      <td>3299</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403162</td>\n",
       "      <td>-0.684917</td>\n",
       "      <td>-0.333361</td>\n",
       "      <td>4.944286</td>\n",
       "      <td>-0.443026</td>\n",
       "      <td>5.576909</td>\n",
       "      <td>0.950999</td>\n",
       "      <td>-1.240911</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2977719</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>Belgien</td>\n",
       "      <td>3382</td>\n",
       "      <td>Panama</td>\n",
       "      <td>3577</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508620</td>\n",
       "      <td>1.578979</td>\n",
       "      <td>2.622755</td>\n",
       "      <td>-0.720146</td>\n",
       "      <td>5.998941</td>\n",
       "      <td>-0.776291</td>\n",
       "      <td>0.516545</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2977725</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Polen</td>\n",
       "      <td>3442</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>3499</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.137992</td>\n",
       "      <td>0.209560</td>\n",
       "      <td>0.797344</td>\n",
       "      <td>1.174830</td>\n",
       "      <td>1.406454</td>\n",
       "      <td>1.342433</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>0.915015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2977726</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Kolumbien</td>\n",
       "      <td>3816</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3435</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.137992</td>\n",
       "      <td>1.444412</td>\n",
       "      <td>0.803472</td>\n",
       "      <td>-0.309383</td>\n",
       "      <td>1.115139</td>\n",
       "      <td>-0.287126</td>\n",
       "      <td>1.385453</td>\n",
       "      <td>0.915015</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gameid tournament  gametype        teamA  teamidA          teamB  \\\n",
       "0   2977683       WM18  Gruppe A     Russland     3448  Saudi-Arabien   \n",
       "1   2977684       WM18  Gruppe A      Ägypten     3672        Uruguay   \n",
       "2   2977690       WM18  Gruppe B     Portugal     3300        Spanien   \n",
       "3   2977689       WM18  Gruppe B      Marokko     3575           Iran   \n",
       "4   2977696       WM18  Gruppe C         Peru     3584       Dänemark   \n",
       "5   2977695       WM18  Gruppe C   Frankreich     3377     Australien   \n",
       "6   2977702       WM18  Gruppe D     Kroatien     3556        Nigeria   \n",
       "7   2977701       WM18  Gruppe D  Argentinien     3437         Island   \n",
       "8   2977708       WM18  Gruppe E    Brasilien     3439        Schweiz   \n",
       "9   2977707       WM18  Gruppe E   Costa Rica     8497        Serbien   \n",
       "10  2977713       WM18  Gruppe F  Deutschland     3262         Mexiko   \n",
       "11  2977714       WM18  Gruppe F     Schweden     3557       Südkorea   \n",
       "12  2977720       WM18  Gruppe G     Tunesien     3670        England   \n",
       "13  2977719       WM18  Gruppe G      Belgien     3382         Panama   \n",
       "14  2977725       WM18  Gruppe H        Polen     3442        Senegal   \n",
       "15  2977726       WM18  Gruppe H    Kolumbien     3816          Japan   \n",
       "\n",
       "    teamidB  resultA  resultB addinfo      ...      teamA_age  teamB_age  \\\n",
       "0      3807        5        0     NaN      ...       1.420402   1.341508   \n",
       "1      3449        0        1     NaN      ...       1.557573   1.001132   \n",
       "2      3375        3        3     NaN      ...       1.137992   1.238603   \n",
       "3      3582        0        1     NaN      ...       0.226210   0.169981   \n",
       "4      3436        0        1     NaN      ...       0.371449   0.241222   \n",
       "5      3433        2        1     NaN      ...      -0.750123   0.929890   \n",
       "6      3444        2        0     NaN      ...       0.750686  -0.795737   \n",
       "7      3574        1        1     NaN      ...       2.090118   1.373171   \n",
       "8      3384        1        1     NaN      ...       1.315507   0.169981   \n",
       "9      3438        0        1     NaN      ...       2.299909  -0.138732   \n",
       "10     6303        0        1     NaN      ...       0.161659   1.856030   \n",
       "11     3589        1        0     NaN      ...       1.000821   0.684503   \n",
       "12     3299        1        2     NaN      ...      -0.403162  -0.684917   \n",
       "13     3577        3        0     NaN      ...       0.508620   1.578979   \n",
       "14     3499        1        2     NaN      ...       1.137992   0.209560   \n",
       "15     3435        1        2     NaN      ...       1.137992   1.444412   \n",
       "\n",
       "    teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  teamA_frag  \\\n",
       "0        0.112267      -0.636883       0.505582      -0.708195   -1.221270   \n",
       "1       -0.333798       1.596695       1.250698       1.949058    0.082092   \n",
       "2        1.889089       7.625774       3.335494       5.612593    0.733772   \n",
       "3       -0.134185      -0.581801       0.281588      -0.397746    1.385453   \n",
       "4       -0.663423       0.811036      -0.461386       1.143794    0.733772   \n",
       "5        6.658797      -0.427231       7.173991      -0.480413   -0.135135   \n",
       "6        1.064370       0.056974       2.314670       0.188658    1.168226   \n",
       "7        1.195695      -0.574970       6.323304      -0.070645    0.516545   \n",
       "8        5.476876       1.717959       6.782308       0.022133   -0.352362   \n",
       "9       -0.328545       0.929738      -0.675588       1.229435    0.733772   \n",
       "10       6.369883      -0.340126       4.958532       0.700125    0.082092   \n",
       "11       0.237026      -0.525439      -0.096631       0.031352    0.733772   \n",
       "12      -0.333361       4.944286      -0.443026       5.576909    0.950999   \n",
       "13       2.622755      -0.720146       5.998941      -0.776291    0.516545   \n",
       "14       0.797344       1.174830       1.406454       1.342433    0.733772   \n",
       "15       0.803472      -0.309383       1.115139      -0.287126    1.385453   \n",
       "\n",
       "    teamB_frag  past_resultA  past_resultB  \n",
       "0    -1.887689          0.00          0.00  \n",
       "1     0.699423          0.00          1.90  \n",
       "2    -0.594133          2.09          3.80  \n",
       "3     0.483830          0.00          0.00  \n",
       "4     0.699423          0.00          0.00  \n",
       "5     1.346201          5.70          0.00  \n",
       "6     1.130608          0.00          0.00  \n",
       "7     1.130608          0.00          0.00  \n",
       "8     0.699423          0.10          1.00  \n",
       "9     1.346201          0.00          0.00  \n",
       "10    0.483830          3.99          1.09  \n",
       "11    0.699423          1.95          1.95  \n",
       "12   -1.240911          0.00          0.00  \n",
       "13    0.699423          0.00          0.00  \n",
       "14    0.915015          0.00          0.00  \n",
       "15    0.915015          3.80          0.95  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "#scale\n",
    "wm[\"teamA_def_val\"]=(wm[\"teamA_def_val\"]-state[\"teamA_def_mean\"])/state[\"teamA_def_std\"]\n",
    "wm[\"teamA_off_val\"]=(wm[\"teamA_off_val\"]-state[\"teamA_off_mean\"])/state[\"teamA_off_std\"]\n",
    "wm[\"teamB_def_val\"]=(wm[\"teamB_def_val\"]-state[\"teamB_def_mean\"])/state[\"teamB_def_std\"]\n",
    "wm[\"teamB_off_val\"]=(wm[\"teamB_off_val\"]-state[\"teamB_off_mean\"])/state[\"teamB_off_std\"]\n",
    "wm[\"teamA_frag\"]=(wm[\"teamA_frag\"]-state[\"teamA_frag_mean\"])/state[\"teamA_frag_std\"]\n",
    "wm[\"teamB_frag\"]=(wm[\"teamB_frag\"]-state[\"teamB_frag_mean\"])/state[\"teamB_frag_std\"]\n",
    "wm[\"teamA_age\"]=(wm[\"teamA_age\"]-state[\"teamA_age_mean\"])/state[\"teamA_age_std\"]\n",
    "wm[\"teamB_age\"]=(wm[\"teamB_age\"]-state[\"teamB_age_mean\"])/state[\"teamB_age_std\"]\n",
    "wm[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates \n",
      " [[2.         0.         0.14992233]]\n",
      "candidates \n",
      " [[0.        1.        0.1486018]]\n",
      "candidates \n",
      " [[0.         1.         0.18752531]]\n",
      "candidates \n",
      " [[1.         0.         0.14686722]]\n",
      "candidates \n",
      " [[0.        1.        0.1537527]]\n",
      "candidates \n",
      " [[1.         0.         0.20177939]]\n",
      "candidates \n",
      " [[1.       0.       0.152191]]\n",
      "candidates \n",
      " [[1.         0.         0.17163099]]\n",
      "candidates \n",
      " [[2.         0.         0.17726191]]\n",
      "candidates \n",
      " [[0.         1.         0.16916594]]\n",
      "candidates \n",
      " [[1.         0.         0.18694237]]\n",
      "candidates \n",
      " [[1.         1.         0.12095687]]\n",
      "candidates \n",
      " [[0.         1.         0.21038033]]\n",
      "candidates \n",
      " [[2.       0.       0.175076]]\n",
      "candidates \n",
      " [[0.         0.         0.13923326]]\n",
      "candidates \n",
      " [[1.         1.         0.13094899]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_tr = torch.from_numpy(wm[0:16][col].values).float()\n",
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy of 56.25%\n",
    "\n",
    "Top-3 accuracy of 31.25%\n",
    "\n",
    "Top-1 accuracy of 18.75%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong prediction for [5 0]\n",
      "candidates \n",
      " [[2.         0.         0.14992233]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.        1.        0.1486018]]\n",
      "wrong prediction for [3 3]\n",
      "candidates \n",
      " [[0.         1.         0.18752531]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.14686722]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.        1.        0.1537527]]\n",
      "wrong prediction for [2 1]\n",
      "candidates \n",
      " [[1.         0.         0.20177939]]\n",
      "wrong prediction for [2 0]\n",
      "candidates \n",
      " [[1.       0.       0.152191]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[1.         0.         0.17163099]]\n",
      "wrong prediction for [1 1]\n",
      "candidates \n",
      " [[2.         0.         0.17726191]]\n",
      "right prediction for [0 1]\n",
      "candidates \n",
      " [[0.         1.         0.16916594]]\n",
      "wrong prediction for [0 1]\n",
      "candidates \n",
      " [[1.         0.         0.18694237]]\n",
      "wrong prediction for [1 0]\n",
      "candidates \n",
      " [[1.         1.         0.12095687]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[0.         1.         0.21038033]]\n",
      "wrong prediction for [3 0]\n",
      "candidates \n",
      " [[2.       0.       0.175076]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[0.         0.         0.13923326]]\n",
      "wrong prediction for [1 2]\n",
      "candidates \n",
      " [[1.         1.         0.13094899]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[0:16][[\"resultA\",\"resultB\"]].values,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.single_tendency(y=wm[0:16][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_tendency(y=wm[0:16][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Spieltag\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.3)\n",
    "state = torch.load('model/model_r2.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process World Cup Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "wm[\"teamA_def_val\"]=(wm[\"teamA_def_val\"]-state[\"teamA_def_mean\"])/state[\"teamA_def_std\"]\n",
    "wm[\"teamA_off_val\"]=(wm[\"teamA_off_val\"]-state[\"teamA_off_mean\"])/state[\"teamA_off_std\"]\n",
    "wm[\"teamB_def_val\"]=(wm[\"teamB_def_val\"]-state[\"teamB_def_mean\"])/state[\"teamB_def_std\"]\n",
    "wm[\"teamB_off_val\"]=(wm[\"teamB_off_val\"]-state[\"teamB_off_mean\"])/state[\"teamB_off_std\"]\n",
    "wm[\"teamA_frag\"]=(wm[\"teamA_frag\"]-state[\"teamA_frag_mean\"])/state[\"teamA_frag_std\"]\n",
    "wm[\"teamB_frag\"]=(wm[\"teamB_frag\"]-state[\"teamB_frag_mean\"])/state[\"teamB_frag_std\"]\n",
    "wm[\"teamA_age\"]=(wm[\"teamA_age\"]-state[\"teamA_age_mean\"])/state[\"teamA_age_std\"]\n",
    "wm[\"teamB_age\"]=(wm[\"teamB_age\"]-state[\"teamB_age_mean\"])/state[\"teamB_age_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>tournament</th>\n",
       "      <th>gametype</th>\n",
       "      <th>teamA</th>\n",
       "      <th>teamidA</th>\n",
       "      <th>teamB</th>\n",
       "      <th>teamidB</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>addinfo</th>\n",
       "      <th>...</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2977686</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3449</td>\n",
       "      <td>Saudi-Arabien</td>\n",
       "      <td>3807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922794</td>\n",
       "      <td>1.268223</td>\n",
       "      <td>1.176461</td>\n",
       "      <td>-0.566439</td>\n",
       "      <td>1.286868</td>\n",
       "      <td>-0.683698</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>-1.911225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2977685</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Russland</td>\n",
       "      <td>3448</td>\n",
       "      <td>Ägypten</td>\n",
       "      <td>3672</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428565</td>\n",
       "      <td>1.499183</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.261908</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>1.421670</td>\n",
       "      <td>-1.351346</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2977692</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Iran</td>\n",
       "      <td>3582</td>\n",
       "      <td>Spanien</td>\n",
       "      <td>3375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066245</td>\n",
       "      <td>1.168140</td>\n",
       "      <td>-0.619397</td>\n",
       "      <td>7.652497</td>\n",
       "      <td>-0.477911</td>\n",
       "      <td>6.288057</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>-0.613035</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2977691</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>3300</td>\n",
       "      <td>Marokko</td>\n",
       "      <td>3575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094103</td>\n",
       "      <td>0.228903</td>\n",
       "      <td>1.374984</td>\n",
       "      <td>-0.068231</td>\n",
       "      <td>2.247523</td>\n",
       "      <td>0.382925</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>1.334252</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2977697</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>3377</td>\n",
       "      <td>Peru</td>\n",
       "      <td>3584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>0.367479</td>\n",
       "      <td>5.210277</td>\n",
       "      <td>-0.581729</td>\n",
       "      <td>5.052564</td>\n",
       "      <td>-0.413434</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.685156</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2977698</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Dänemark</td>\n",
       "      <td>3436</td>\n",
       "      <td>Australien</td>\n",
       "      <td>3433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139664</td>\n",
       "      <td>0.867892</td>\n",
       "      <td>0.528798</td>\n",
       "      <td>-0.357897</td>\n",
       "      <td>0.681315</td>\n",
       "      <td>-0.432458</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>1.334252</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2977703</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Argentinien</td>\n",
       "      <td>3437</td>\n",
       "      <td>Kroatien</td>\n",
       "      <td>3556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.056700</td>\n",
       "      <td>0.729316</td>\n",
       "      <td>0.817430</td>\n",
       "      <td>1.094677</td>\n",
       "      <td>4.430911</td>\n",
       "      <td>2.562091</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>1.117886</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2977704</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>3444</td>\n",
       "      <td>Island</td>\n",
       "      <td>3574</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.928982</td>\n",
       "      <td>1.299017</td>\n",
       "      <td>-0.092818</td>\n",
       "      <td>-0.504853</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>1.158577</td>\n",
       "      <td>1.117886</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2977710</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Serbien</td>\n",
       "      <td>3438</td>\n",
       "      <td>Schweiz</td>\n",
       "      <td>3384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251901</td>\n",
       "      <td>0.128820</td>\n",
       "      <td>0.626651</td>\n",
       "      <td>-0.740153</td>\n",
       "      <td>0.745717</td>\n",
       "      <td>0.121845</td>\n",
       "      <td>1.386752</td>\n",
       "      <td>0.685156</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2977709</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Brasilien</td>\n",
       "      <td>3439</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>8497</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.273570</td>\n",
       "      <td>2.207460</td>\n",
       "      <td>4.259901</td>\n",
       "      <td>-0.256811</td>\n",
       "      <td>4.766335</td>\n",
       "      <td>-0.643027</td>\n",
       "      <td>-0.438646</td>\n",
       "      <td>0.685156</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2977715</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>3262</td>\n",
       "      <td>Schweden</td>\n",
       "      <td>3557</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107033</td>\n",
       "      <td>0.967975</td>\n",
       "      <td>4.977963</td>\n",
       "      <td>0.291939</td>\n",
       "      <td>3.433583</td>\n",
       "      <td>-0.022470</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>0.685156</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2977716</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Südkorea</td>\n",
       "      <td>3589</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>6303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596490</td>\n",
       "      <td>1.768636</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-0.271252</td>\n",
       "      <td>-0.155233</td>\n",
       "      <td>0.869663</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>0.468791</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2977721</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>Belgien</td>\n",
       "      <td>3382</td>\n",
       "      <td>Tunesien</td>\n",
       "      <td>3670</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457810</td>\n",
       "      <td>-0.371593</td>\n",
       "      <td>1.964920</td>\n",
       "      <td>-0.261483</td>\n",
       "      <td>4.193878</td>\n",
       "      <td>-0.393755</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>0.901521</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2977722</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>England</td>\n",
       "      <td>3299</td>\n",
       "      <td>Panama</td>\n",
       "      <td>3577</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>1.499183</td>\n",
       "      <td>3.936069</td>\n",
       "      <td>-0.649261</td>\n",
       "      <td>4.014985</td>\n",
       "      <td>-0.758808</td>\n",
       "      <td>-1.351346</td>\n",
       "      <td>0.685156</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2977728</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Polen</td>\n",
       "      <td>3442</td>\n",
       "      <td>Kolumbien</td>\n",
       "      <td>3816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094103</td>\n",
       "      <td>1.098852</td>\n",
       "      <td>0.497118</td>\n",
       "      <td>0.841539</td>\n",
       "      <td>0.837847</td>\n",
       "      <td>1.276370</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>1.334252</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2977727</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3435</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>3499</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379619</td>\n",
       "      <td>0.167313</td>\n",
       "      <td>-0.394827</td>\n",
       "      <td>1.235688</td>\n",
       "      <td>-0.394726</td>\n",
       "      <td>1.578121</td>\n",
       "      <td>0.930403</td>\n",
       "      <td>0.901521</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gameid tournament  gametype        teamA  teamidA          teamB  \\\n",
       "16  2977686       WM18  Gruppe A      Uruguay     3449  Saudi-Arabien   \n",
       "17  2977685       WM18  Gruppe A     Russland     3448        Ägypten   \n",
       "18  2977692       WM18  Gruppe B         Iran     3582        Spanien   \n",
       "19  2977691       WM18  Gruppe B     Portugal     3300        Marokko   \n",
       "20  2977697       WM18  Gruppe C   Frankreich     3377           Peru   \n",
       "21  2977698       WM18  Gruppe C     Dänemark     3436     Australien   \n",
       "22  2977703       WM18  Gruppe D  Argentinien     3437       Kroatien   \n",
       "23  2977704       WM18  Gruppe D      Nigeria     3444         Island   \n",
       "24  2977710       WM18  Gruppe E      Serbien     3438        Schweiz   \n",
       "25  2977709       WM18  Gruppe E    Brasilien     3439     Costa Rica   \n",
       "26  2977715       WM18  Gruppe F  Deutschland     3262       Schweden   \n",
       "27  2977716       WM18  Gruppe F     Südkorea     3589         Mexiko   \n",
       "28  2977721       WM18  Gruppe G      Belgien     3382       Tunesien   \n",
       "29  2977722       WM18  Gruppe G      England     3299         Panama   \n",
       "30  2977728       WM18  Gruppe H        Polen     3442      Kolumbien   \n",
       "31  2977727       WM18  Gruppe H        Japan     3435        Senegal   \n",
       "\n",
       "    teamidB  resultA  resultB addinfo      ...      teamA_age  teamB_age  \\\n",
       "16     3807      1.0      0.0     NaN      ...       0.922794   1.268223   \n",
       "17     3672      3.0      1.0     NaN      ...       1.428565   1.499183   \n",
       "18     3375      0.0      1.0     NaN      ...       0.066245   1.168140   \n",
       "19     3575      1.0      0.0     NaN      ...       1.094103   0.228903   \n",
       "20     3584      1.0      0.0     NaN      ...      -0.814776   0.367479   \n",
       "21     3433      1.0      1.0     NaN      ...       0.139664   0.867892   \n",
       "22     3556      0.0      3.0     NaN      ...       2.056700   0.729316   \n",
       "23     3574      2.0      0.0     NaN      ...      -0.928982   1.299017   \n",
       "24     3384      1.0      2.0     NaN      ...      -0.251901   0.128820   \n",
       "25     8497      2.0      0.0     NaN      ...       1.273570   2.207460   \n",
       "26     3557      2.0      1.0     NaN      ...       0.107033   0.967975   \n",
       "27     6303      1.0      2.0     NaN      ...       0.596490   1.768636   \n",
       "28     3670      5.0      2.0     NaN      ...       0.457810  -0.371593   \n",
       "29     3577      6.0      1.0     NaN      ...      -0.814776   1.499183   \n",
       "30     3816      0.0      3.0     NaN      ...       1.094103   1.098852   \n",
       "31     3499      2.0      2.0     NaN      ...       1.379619   0.167313   \n",
       "\n",
       "    teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  teamA_frag  \\\n",
       "16       1.176461      -0.566439       1.286868      -0.683698    0.702228   \n",
       "17      -0.053747      -0.261908       0.045351       1.421670   -1.351346   \n",
       "18      -0.619397       7.652497      -0.477911       6.288057    0.474053   \n",
       "19       1.374984      -0.068231       2.247523       0.382925    0.702228   \n",
       "20       5.210277      -0.581729       5.052564      -0.413434   -0.210472   \n",
       "21       0.528798      -0.357897       0.681315      -0.432458    0.702228   \n",
       "22       0.817430       1.094677       4.430911       2.562091    0.474053   \n",
       "23      -0.092818      -0.504853      -0.036940       0.019513    1.158577   \n",
       "24       0.626651      -0.740153       0.745717       0.121845    1.386752   \n",
       "25       4.259901      -0.256811       4.766335      -0.643027   -0.438646   \n",
       "26       4.977963       0.291939       3.433583      -0.022470    0.017703   \n",
       "27      -0.572934      -0.271252      -0.155233       0.869663    0.702228   \n",
       "28       1.964920      -0.261483       4.193878      -0.393755    0.474053   \n",
       "29       3.936069      -0.649261       4.014985      -0.758808   -1.351346   \n",
       "30       0.497118       0.841539       0.837847       1.276370    0.702228   \n",
       "31      -0.394827       1.235688      -0.394726       1.578121    0.930403   \n",
       "\n",
       "    teamB_frag  past_resultA  past_resultB  \n",
       "16   -1.911225          0.00          0.00  \n",
       "17    0.036061          0.00          0.00  \n",
       "18   -0.613035          0.00          0.00  \n",
       "19    1.334252          0.00          0.00  \n",
       "20    0.685156          0.00          0.00  \n",
       "21    1.334252          0.00          0.00  \n",
       "22    1.117886          0.00          0.00  \n",
       "23    1.117886          0.00          0.00  \n",
       "24    0.685156          0.00          0.00  \n",
       "25    0.685156          1.01          0.00  \n",
       "26    0.685156          4.94          3.04  \n",
       "27    0.468791          0.05          3.80  \n",
       "28    0.901521          0.95          0.00  \n",
       "29    0.685156          0.95          1.90  \n",
       "30    1.334252          0.00          0.00  \n",
       "31    0.901521          0.95          0.00  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm[16:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[16:32][col].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates \n",
      " [[2.        0.        0.1408494]]\n",
      "candidates \n",
      " [[0.         1.         0.15445287]]\n",
      "candidates \n",
      " [[0.         2.         0.15739525]]\n",
      "candidates \n",
      " [[1.        0.        0.1586748]]\n",
      "candidates \n",
      " [[1.         0.         0.18686738]]\n",
      "candidates \n",
      " [[1.         0.         0.15315448]]\n",
      "candidates \n",
      " [[0.         0.         0.13424797]]\n",
      "candidates \n",
      " [[1.         0.         0.14404709]]\n",
      "candidates \n",
      " [[1.         0.         0.14479188]]\n",
      "candidates \n",
      " [[1.         0.         0.19961584]]\n",
      "candidates \n",
      " [[0.       0.       0.168282]]\n",
      "candidates \n",
      " [[1.         1.         0.12689939]]\n",
      "candidates \n",
      " [[1.         0.         0.18026515]]\n",
      "candidates \n",
      " [[1.        0.        0.1615339]]\n",
      "candidates \n",
      " [[0.         0.         0.13958506]]\n",
      "candidates \n",
      " [[0.         1.         0.15794784]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy of 50%\n",
    "\n",
    "Top-3 accuracy of 37.5%\n",
    "\n",
    "Top-1 accuracy of 12.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right prediction for [1. 0.]\n",
      "candidates \n",
      " [[2.         0.         0.1408494 ]\n",
      " [3.         0.         0.12900243]\n",
      " [1.         0.         0.10569544]]\n",
      "wrong prediction for [3. 1.]\n",
      "candidates \n",
      " [[0.         1.         0.15445287]\n",
      " [0.         2.         0.12431943]\n",
      " [0.         0.         0.11038576]]\n",
      "right prediction for [0. 1.]\n",
      "candidates \n",
      " [[0.         2.         0.15739525]\n",
      " [0.         3.         0.13457123]\n",
      " [0.         1.         0.12376535]]\n",
      "right prediction for [1. 0.]\n",
      "candidates \n",
      " [[1.         0.         0.1586748 ]\n",
      " [0.         0.         0.13731201]\n",
      " [1.         1.         0.12405293]]\n",
      "right prediction for [1. 0.]\n",
      "candidates \n",
      " [[1.         0.         0.18686738]\n",
      " [2.         0.         0.15924968]\n",
      " [0.         0.         0.10997625]]\n",
      "right prediction for [1. 1.]\n",
      "candidates \n",
      " [[1.         0.         0.15315448]\n",
      " [1.         1.         0.11749234]\n",
      " [0.         0.         0.11254028]]\n",
      "wrong prediction for [0. 3.]\n",
      "candidates \n",
      " [[0.         0.         0.13424797]\n",
      " [1.         0.         0.13033704]\n",
      " [0.         1.         0.12884998]]\n",
      "wrong prediction for [2. 0.]\n",
      "candidates \n",
      " [[1.         0.         0.14404709]\n",
      " [1.         1.         0.12354867]\n",
      " [0.         0.         0.11113199]]\n",
      "wrong prediction for [1. 2.]\n",
      "candidates \n",
      " [[1.         0.         0.14479188]\n",
      " [1.         1.         0.12410043]\n",
      " [0.         0.         0.1112535 ]]\n",
      "right prediction for [2. 0.]\n",
      "candidates \n",
      " [[1.         0.         0.19961584]\n",
      " [2.         0.         0.15544385]\n",
      " [0.         0.         0.12891145]]\n",
      "wrong prediction for [2. 1.]\n",
      "candidates \n",
      " [[0.         0.         0.168282  ]\n",
      " [1.         0.         0.16086257]\n",
      " [0.         1.         0.13850743]]\n",
      "wrong prediction for [1. 2.]\n",
      "candidates \n",
      " [[1.         1.         0.12689939]\n",
      " [0.         1.         0.11916783]\n",
      " [1.         0.         0.11183653]]\n",
      "wrong prediction for [5. 2.]\n",
      "candidates \n",
      " [[1.         0.         0.18026515]\n",
      " [0.         0.         0.13041792]\n",
      " [2.         0.         0.1266513 ]]\n",
      "wrong prediction for [6. 1.]\n",
      "candidates \n",
      " [[1.         0.         0.1615339 ]\n",
      " [2.         0.         0.15648643]\n",
      " [3.         0.         0.10184976]]\n",
      "wrong prediction for [0. 3.]\n",
      "candidates \n",
      " [[0.         0.         0.13958506]\n",
      " [0.         1.         0.13210453]\n",
      " [1.         0.         0.12442048]]\n",
      "wrong prediction for [2. 2.]\n",
      "candidates \n",
      " [[0.         1.         0.15794784]\n",
      " [0.         0.         0.14006966]\n",
      " [1.         1.         0.11694084]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[16:32][[\"resultA\",\"resultB\"]].values,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.single_tendency(y=wm[16:32][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_tendency(y=wm[16:32][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm_tr.requires_grad_()\n",
    "#muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "#end = muA.mean()\n",
    "#end.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Spieltag\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.3)\n",
    "state = torch.load('model/model_r3.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "#scale\n",
    "wm[\"teamA_def_val\"]=(wm[\"teamA_def_val\"]-state[\"teamA_def_mean\"])/state[\"teamA_def_std\"]\n",
    "wm[\"teamA_off_val\"]=(wm[\"teamA_off_val\"]-state[\"teamA_off_mean\"])/state[\"teamA_off_std\"]\n",
    "wm[\"teamB_def_val\"]=(wm[\"teamB_def_val\"]-state[\"teamB_def_mean\"])/state[\"teamB_def_std\"]\n",
    "wm[\"teamB_off_val\"]=(wm[\"teamB_off_val\"]-state[\"teamB_off_mean\"])/state[\"teamB_off_std\"]\n",
    "wm[\"teamA_frag\"]=(wm[\"teamA_frag\"]-state[\"teamA_frag_mean\"])/state[\"teamA_frag_std\"]\n",
    "wm[\"teamB_frag\"]=(wm[\"teamB_frag\"]-state[\"teamB_frag_mean\"])/state[\"teamB_frag_std\"]\n",
    "wm[\"teamA_age\"]=(wm[\"teamA_age\"]-state[\"teamA_age_mean\"])/state[\"teamA_age_std\"]\n",
    "wm[\"teamB_age\"]=(wm[\"teamB_age\"]-state[\"teamB_age_mean\"])/state[\"teamB_age_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>tournament</th>\n",
       "      <th>gametype</th>\n",
       "      <th>teamA</th>\n",
       "      <th>teamidA</th>\n",
       "      <th>teamB</th>\n",
       "      <th>teamidB</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>addinfo</th>\n",
       "      <th>...</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2977687</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3449</td>\n",
       "      <td>Russland</td>\n",
       "      <td>3448</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940840</td>\n",
       "      <td>1.380574</td>\n",
       "      <td>1.048937</td>\n",
       "      <td>0.144698</td>\n",
       "      <td>1.144058</td>\n",
       "      <td>0.372546</td>\n",
       "      <td>0.723213</td>\n",
       "      <td>-1.246889</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2977688</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe A</td>\n",
       "      <td>Saudi-Arabien</td>\n",
       "      <td>3807</td>\n",
       "      <td>Ägypten</td>\n",
       "      <td>3672</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232466</td>\n",
       "      <td>1.464562</td>\n",
       "      <td>-0.668931</td>\n",
       "      <td>-0.270062</td>\n",
       "      <td>-0.710576</td>\n",
       "      <td>1.302292</td>\n",
       "      <td>-1.933487</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2977694</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Spanien</td>\n",
       "      <td>3375</td>\n",
       "      <td>Marokko</td>\n",
       "      <td>3575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190805</td>\n",
       "      <td>0.204733</td>\n",
       "      <td>5.685966</td>\n",
       "      <td>-0.084458</td>\n",
       "      <td>3.682281</td>\n",
       "      <td>0.332109</td>\n",
       "      <td>-0.605137</td>\n",
       "      <td>1.302359</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2977693</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe B</td>\n",
       "      <td>Iran</td>\n",
       "      <td>3582</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>3300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065963</td>\n",
       "      <td>1.067525</td>\n",
       "      <td>-0.626567</td>\n",
       "      <td>1.796816</td>\n",
       "      <td>-0.481889</td>\n",
       "      <td>3.389396</td>\n",
       "      <td>0.501821</td>\n",
       "      <td>0.665047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2977700</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Australien</td>\n",
       "      <td>3433</td>\n",
       "      <td>Peru</td>\n",
       "      <td>3584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965836</td>\n",
       "      <td>0.342169</td>\n",
       "      <td>-0.507686</td>\n",
       "      <td>-0.576552</td>\n",
       "      <td>-0.543696</td>\n",
       "      <td>-0.411688</td>\n",
       "      <td>1.165996</td>\n",
       "      <td>0.665047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2977699</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe C</td>\n",
       "      <td>Dänemark</td>\n",
       "      <td>3436</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>3377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100680</td>\n",
       "      <td>-0.719142</td>\n",
       "      <td>0.438110</td>\n",
       "      <td>6.231770</td>\n",
       "      <td>0.586143</td>\n",
       "      <td>7.232143</td>\n",
       "      <td>0.723213</td>\n",
       "      <td>-0.184702</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2977706</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Island</td>\n",
       "      <td>3574</td>\n",
       "      <td>Kroatien</td>\n",
       "      <td>3556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.332452</td>\n",
       "      <td>0.701029</td>\n",
       "      <td>-0.621313</td>\n",
       "      <td>1.029979</td>\n",
       "      <td>-0.255262</td>\n",
       "      <td>2.367441</td>\n",
       "      <td>1.165996</td>\n",
       "      <td>1.089922</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2977705</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe D</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>3444</td>\n",
       "      <td>Argentinien</td>\n",
       "      <td>3437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950561</td>\n",
       "      <td>1.968494</td>\n",
       "      <td>-0.135279</td>\n",
       "      <td>1.152087</td>\n",
       "      <td>-0.075608</td>\n",
       "      <td>6.380514</td>\n",
       "      <td>1.165996</td>\n",
       "      <td>0.452610</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2977712</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Schweiz</td>\n",
       "      <td>3384</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>8497</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065963</td>\n",
       "      <td>2.167013</td>\n",
       "      <td>1.142203</td>\n",
       "      <td>-0.265177</td>\n",
       "      <td>-0.190982</td>\n",
       "      <td>-0.626127</td>\n",
       "      <td>0.723213</td>\n",
       "      <td>0.665047</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2977711</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe E</td>\n",
       "      <td>Serbien</td>\n",
       "      <td>3438</td>\n",
       "      <td>Brasilien</td>\n",
       "      <td>3439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258991</td>\n",
       "      <td>1.311856</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>4.807179</td>\n",
       "      <td>0.645478</td>\n",
       "      <td>6.840026</td>\n",
       "      <td>1.387388</td>\n",
       "      <td>-0.397140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2977717</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Südkorea</td>\n",
       "      <td>3589</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>3262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>-0.583218</td>\n",
       "      <td>4.986271</td>\n",
       "      <td>-0.184595</td>\n",
       "      <td>5.014231</td>\n",
       "      <td>0.723213</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2977718</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe F</td>\n",
       "      <td>Mexiko</td>\n",
       "      <td>6303</td>\n",
       "      <td>Schweden</td>\n",
       "      <td>3557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.840713</td>\n",
       "      <td>0.937725</td>\n",
       "      <td>-0.440692</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.278754</td>\n",
       "      <td>-0.046529</td>\n",
       "      <td>0.501821</td>\n",
       "      <td>0.665047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2977723</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>England</td>\n",
       "      <td>3299</td>\n",
       "      <td>Belgien</td>\n",
       "      <td>3382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833911</td>\n",
       "      <td>0.471969</td>\n",
       "      <td>3.623605</td>\n",
       "      <td>2.478991</td>\n",
       "      <td>3.657558</td>\n",
       "      <td>6.055792</td>\n",
       "      <td>-1.269312</td>\n",
       "      <td>0.452610</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2977724</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe G</td>\n",
       "      <td>Panama</td>\n",
       "      <td>3577</td>\n",
       "      <td>Tunesien</td>\n",
       "      <td>3670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549088</td>\n",
       "      <td>-0.238116</td>\n",
       "      <td>-0.732969</td>\n",
       "      <td>-0.355944</td>\n",
       "      <td>-0.744158</td>\n",
       "      <td>-0.393308</td>\n",
       "      <td>0.723213</td>\n",
       "      <td>0.877484</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2977731</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3435</td>\n",
       "      <td>Polen</td>\n",
       "      <td>3442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407441</td>\n",
       "      <td>1.067525</td>\n",
       "      <td>-0.417047</td>\n",
       "      <td>0.781693</td>\n",
       "      <td>-0.405248</td>\n",
       "      <td>1.458220</td>\n",
       "      <td>0.944604</td>\n",
       "      <td>0.665047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2977730</td>\n",
       "      <td>WM18</td>\n",
       "      <td>Gruppe H</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>3499</td>\n",
       "      <td>Kolumbien</td>\n",
       "      <td>3816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>1.067525</td>\n",
       "      <td>0.724476</td>\n",
       "      <td>0.787392</td>\n",
       "      <td>0.723767</td>\n",
       "      <td>1.166583</td>\n",
       "      <td>0.944604</td>\n",
       "      <td>1.302359</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gameid tournament  gametype          teamA  teamidA        teamB  \\\n",
       "32  2977687       WM18  Gruppe A        Uruguay     3449     Russland   \n",
       "33  2977688       WM18  Gruppe A  Saudi-Arabien     3807      Ägypten   \n",
       "34  2977694       WM18  Gruppe B        Spanien     3375      Marokko   \n",
       "35  2977693       WM18  Gruppe B           Iran     3582     Portugal   \n",
       "36  2977700       WM18  Gruppe C     Australien     3433         Peru   \n",
       "37  2977699       WM18  Gruppe C       Dänemark     3436   Frankreich   \n",
       "38  2977706       WM18  Gruppe D         Island     3574     Kroatien   \n",
       "39  2977705       WM18  Gruppe D        Nigeria     3444  Argentinien   \n",
       "40  2977712       WM18  Gruppe E        Schweiz     3384   Costa Rica   \n",
       "41  2977711       WM18  Gruppe E        Serbien     3438    Brasilien   \n",
       "42  2977717       WM18  Gruppe F       Südkorea     3589  Deutschland   \n",
       "43  2977718       WM18  Gruppe F         Mexiko     6303     Schweden   \n",
       "44  2977723       WM18  Gruppe G        England     3299      Belgien   \n",
       "45  2977724       WM18  Gruppe G         Panama     3577     Tunesien   \n",
       "46  2977731       WM18  Gruppe H          Japan     3435        Polen   \n",
       "47  2977730       WM18  Gruppe H        Senegal     3499    Kolumbien   \n",
       "\n",
       "    teamidB  resultA  resultB addinfo      ...      teamA_age  teamB_age  \\\n",
       "32     3448      2.0      0.0     NaN      ...       0.940840   1.380574   \n",
       "33     3672      2.0      1.0     NaN      ...       1.232466   1.464562   \n",
       "34     3575      2.0      2.0     NaN      ...       1.190805   0.204733   \n",
       "35     3300      1.0      1.0     NaN      ...       0.065963   1.067525   \n",
       "36     3584      0.0      2.0     NaN      ...       0.965836   0.342169   \n",
       "37     3377      0.0      0.0     NaN      ...      -0.100680  -0.719142   \n",
       "38     3556      1.0      2.0     NaN      ...       1.332452   0.701029   \n",
       "39     3437      1.0      2.0     NaN      ...      -0.950561   1.968494   \n",
       "40     8497      2.0      2.0     NaN      ...       0.065963   2.167013   \n",
       "41     3439      0.0      2.0     NaN      ...      -0.258991   1.311856   \n",
       "42     3262      2.0      0.0     NaN      ...       0.607553   0.006214   \n",
       "43     3557      0.0      3.0     NaN      ...       1.840713   0.937725   \n",
       "44     3382      0.0      1.0     NaN      ...      -0.833911   0.471969   \n",
       "45     3670      1.0      2.0     NaN      ...       1.549088  -0.238116   \n",
       "46     3442      0.0      1.0     NaN      ...       1.407441   1.067525   \n",
       "47     3816      0.0      1.0     NaN      ...       0.107624   1.067525   \n",
       "\n",
       "    teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  teamA_frag  \\\n",
       "32       1.048937       0.144698       1.144058       0.372546    0.723213   \n",
       "33      -0.668931      -0.270062      -0.710576       1.302292   -1.933487   \n",
       "34       5.685966      -0.084458       3.682281       0.332109   -0.605137   \n",
       "35      -0.626567       1.796816      -0.481889       3.389396    0.501821   \n",
       "36      -0.507686      -0.576552      -0.543696      -0.411688    1.165996   \n",
       "37       0.438110       6.231770       0.586143       7.232143    0.723213   \n",
       "38      -0.621313       1.029979      -0.255262       2.367441    1.165996   \n",
       "39      -0.135279       1.152087      -0.075608       6.380514    1.165996   \n",
       "40       1.142203      -0.265177      -0.190982      -0.626127    0.723213   \n",
       "41       0.535974       4.807179       0.645478       6.840026    1.387388   \n",
       "42      -0.583218       4.986271      -0.184595       5.014231    0.723213   \n",
       "43      -0.440692       0.260700       0.278754      -0.046529    0.501821   \n",
       "44       3.623605       2.478991       3.657558       6.055792   -1.269312   \n",
       "45      -0.732969      -0.355944      -0.744158      -0.393308    0.723213   \n",
       "46      -0.417047       0.781693      -0.405248       1.458220    0.944604   \n",
       "47       0.724476       0.787392       0.723767       1.166583    0.944604   \n",
       "\n",
       "    teamB_frag  past_resultA  past_resultB  \n",
       "32   -1.246889          0.95          0.95  \n",
       "33    0.027735          0.95          1.95  \n",
       "34    1.302359          0.00          0.00  \n",
       "35    0.665047          0.00          1.90  \n",
       "36    0.665047          0.00          0.00  \n",
       "37   -0.184702          0.95          2.00  \n",
       "38    1.089922          0.95          0.10  \n",
       "39    0.452610          3.90          2.05  \n",
       "40    0.665047          0.10          0.95  \n",
       "41   -0.397140          0.00          0.95  \n",
       "42    0.027735          2.85          0.95  \n",
       "43    0.665047          0.00          0.95  \n",
       "44    0.452610          0.95          0.00  \n",
       "45    0.877484          0.00          0.00  \n",
       "46    0.665047          0.00          0.00  \n",
       "47    1.302359          1.90          1.90  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm[32:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr = torch.from_numpy(wm[32:48][col].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates \n",
      " [[1.        0.        0.1366892]]\n",
      "candidates \n",
      " [[0.         2.         0.14351279]]\n",
      "candidates \n",
      " [[2.         0.         0.17812292]]\n",
      "candidates \n",
      " [[0.         1.         0.21517396]]\n",
      "candidates \n",
      " [[1.         1.         0.12842429]]\n",
      "candidates \n",
      " [[0.         1.         0.30006071]]\n",
      "candidates \n",
      " [[0.         2.         0.13592741]]\n",
      "candidates \n",
      " [[1.         2.         0.09098509]]\n",
      "candidates \n",
      " [[1.         0.         0.15842456]]\n",
      "candidates \n",
      " [[0.         2.         0.20304446]]\n",
      "candidates \n",
      " [[0.         1.         0.22965621]]\n",
      "candidates \n",
      " [[1.         1.         0.12918017]]\n",
      "candidates \n",
      " [[1.         1.         0.12307567]]\n",
      "candidates \n",
      " [[1.         1.         0.13048052]]\n",
      "candidates \n",
      " [[0.         1.         0.12770414]]\n",
      "candidates \n",
      " [[1.        1.        0.1296417]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 accuracy 62.5%\n",
    "\n",
    "Top-3 accuracy 43.75%\n",
    "\n",
    "Top-1 accuracy 18.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right prediction for [2. 0.]\n",
      "candidates \n",
      " [[1.         0.         0.1366892 ]\n",
      " [1.         1.         0.12168228]\n",
      " [2.         0.         0.09857692]]\n",
      "wrong prediction for [2. 1.]\n",
      "candidates \n",
      " [[0.         2.         0.14351279]\n",
      " [0.         1.         0.14059555]\n",
      " [0.         3.         0.09868203]]\n",
      "wrong prediction for [2. 2.]\n",
      "candidates \n",
      " [[2.         0.         0.17812292]\n",
      " [1.         0.         0.1777686 ]\n",
      " [3.         0.         0.11909493]]\n",
      "wrong prediction for [1. 1.]\n",
      "candidates \n",
      " [[0.         1.         0.21517396]\n",
      " [0.         2.         0.17225352]\n",
      " [0.         0.         0.13449624]]\n",
      "wrong prediction for [0. 2.]\n",
      "candidates \n",
      " [[1.         1.         0.12842429]\n",
      " [1.         0.         0.10680045]\n",
      " [0.         1.         0.10622583]]\n",
      "right prediction for [0. 0.]\n",
      "candidates \n",
      " [[0.         1.         0.30006071]\n",
      " [0.         2.         0.21337062]\n",
      " [0.         0.         0.2109876 ]]\n",
      "wrong prediction for [1. 2.]\n",
      "candidates \n",
      " [[0.         2.         0.13592741]\n",
      " [0.         1.         0.12093135]\n",
      " [0.         3.         0.10189856]]\n",
      "right prediction for [1. 2.]\n",
      "candidates \n",
      " [[1.         2.         0.09098509]\n",
      " [0.         2.         0.08789769]\n",
      " [1.         3.         0.0806661 ]]\n",
      "wrong prediction for [2. 2.]\n",
      "candidates \n",
      " [[1.         0.         0.15842456]\n",
      " [2.         0.         0.1189942 ]\n",
      " [1.         1.         0.11638792]]\n",
      "right prediction for [0. 2.]\n",
      "candidates \n",
      " [[0.         2.         0.20304446]\n",
      " [0.         3.         0.17272401]\n",
      " [0.         1.         0.1591286 ]]\n",
      "wrong prediction for [2. 0.]\n",
      "candidates \n",
      " [[0.         1.         0.22965621]\n",
      " [0.         2.         0.21672427]\n",
      " [0.         3.         0.13634998]]\n",
      "wrong prediction for [0. 3.]\n",
      "candidates \n",
      " [[1.         1.         0.12918017]\n",
      " [0.         1.         0.1129895 ]\n",
      " [1.         0.         0.10439735]]\n",
      "right prediction for [0. 1.]\n",
      "candidates \n",
      " [[1.         1.         0.12307567]\n",
      " [0.         1.         0.09815298]\n",
      " [1.         0.         0.0896524 ]]\n",
      "wrong prediction for [1. 2.]\n",
      "candidates \n",
      " [[1.         1.         0.13048052]\n",
      " [0.         1.         0.12283635]\n",
      " [1.         0.         0.10496143]]\n",
      "right prediction for [0. 1.]\n",
      "candidates \n",
      " [[0.         1.         0.12770414]\n",
      " [0.         2.         0.12516125]\n",
      " [1.         1.         0.09781687]]\n",
      "right prediction for [0. 1.]\n",
      "candidates \n",
      " [[1.         1.         0.1296417 ]\n",
      " [0.         1.         0.10991569]\n",
      " [1.         0.         0.10483588]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_result(y_prob=probs,y=wm[32:48][[\"resultA\",\"resultB\"]].values,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.single_tendency(y=wm[32:48][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_tendency(y=wm[32:48][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr.requires_grad_()\n",
    "#wm_tr.grad.data.zero_()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "expA = muA.mean()\n",
    "expA.backward()\n",
    "wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr.grad.data.zero_()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "expB = muB.mean()\n",
    "expB.backward()\n",
    "wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr.grad.data.zero_()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "disB = alphaB.mean()\n",
    "disB.backward()\n",
    "wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tr.grad.data.zero_()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "disA = alphaA.mean()\n",
    "disA.backward()\n",
    "wm_tr.grad.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knockout Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[\"gametype\",\"teamA_age\",\"teamB_age\",\"teamA_def_val\",\"teamB_def_val\",\"teamA_off_val\",\"teamB_off_val\",\"teamA_frag\",\"teamB_frag\",\"past_resultA\",\"past_resultB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achtelfinale\n",
    "#neural_pickled = NBNet(len(col),30,30,4,0.25)\n",
    "#state = torch.load('model/model_ko16.pth')\n",
    "# Viertelfinale\n",
    "neural_pickled = NBNet(len(col),30,20,4,0.25)\n",
    "state = torch.load('model/model_ko8.pth')\n",
    "neural_pickled.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(filepath_or_buffer=\"data/WM18.csv\",delimiter=\";\",index_col=False).round(2)\n",
    "# impute missing past values with 0\n",
    "wm.fillna({\"past_resultA\":0,\"past_resultB\":0},inplace=True)\n",
    "#scale\n",
    "wm[\"teamA_def_val\"]=(wm[\"teamA_def_val\"]-state[\"teamA_def_mean\"])/state[\"teamA_def_std\"]\n",
    "wm[\"teamA_off_val\"]=(wm[\"teamA_off_val\"]-state[\"teamA_off_mean\"])/state[\"teamA_off_std\"]\n",
    "wm[\"teamB_def_val\"]=(wm[\"teamB_def_val\"]-state[\"teamB_def_mean\"])/state[\"teamB_def_std\"]\n",
    "wm[\"teamB_off_val\"]=(wm[\"teamB_off_val\"]-state[\"teamB_off_mean\"])/state[\"teamB_off_std\"]\n",
    "wm[\"teamA_frag\"]=(wm[\"teamA_frag\"]-state[\"teamA_frag_mean\"])/state[\"teamA_frag_std\"]\n",
    "wm[\"teamB_frag\"]=(wm[\"teamB_frag\"]-state[\"teamB_frag_mean\"])/state[\"teamB_frag_std\"]\n",
    "wm[\"teamA_age\"]=(wm[\"teamA_age\"]-state[\"teamA_age_mean\"])/state[\"teamA_age_std\"]\n",
    "wm[\"teamB_age\"]=(wm[\"teamB_age\"]-state[\"teamB_age_mean\"])/state[\"teamB_age_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode gametype\n",
    "rounds = {\n",
    "    \"Finale\": 1,\n",
    "    \"Spiel um Platz Drei\": 2,\n",
    "    \"Halbfinale\": 3,\n",
    "    \"Viertelfinale\": 4,\n",
    "    \"Achtelfinale\": 5,\n",
    "    \"Gruppenphase\": 6\n",
    "}\n",
    "def map_to_round(x):\n",
    "    if x.startswith(\"Gruppe\"):\n",
    "        return rounds[\"Gruppenphase\"]\n",
    "    else:\n",
    "        return rounds[x]\n",
    "wm[\"gametype\"]=wm[\"gametype\"].apply(map_to_round)\n",
    "\n",
    "# Achtelfinale\n",
    "#wm_tr = torch.from_numpy(wm[48:56][col].values).float()\n",
    "# Viertelfinale\n",
    "wm_tr = torch.from_numpy(wm[56:60][col].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates \n",
      " [[1.         0.         0.11342321]\n",
      " [1.         1.         0.104496  ]\n",
      " [0.         0.         0.08822611]]\n",
      "candidates \n",
      " [[0.         1.         0.14685746]\n",
      " [0.         0.         0.12976716]\n",
      " [0.         2.         0.11458328]]\n",
      "candidates \n",
      " [[0.         0.         0.12782252]\n",
      " [0.         1.         0.11566763]\n",
      " [1.         0.         0.11556682]]\n",
      "candidates \n",
      " [[0.         1.         0.1436295 ]\n",
      " [0.         0.         0.12048139]\n",
      " [0.         2.         0.11516628]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pickled.eval()\n",
    "muA,alphaA,muB,alphaB=neural_pickled(wm_tr)\n",
    "muA,alphaA,muB,alphaB=to_numpy(muA,alphaA,muB,alphaB)\n",
    "probs = util.calc_nb_probs(muA,alphaA,muB,alphaB)\n",
    "util.multi_result(y_prob=probs,top_n=3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#util.single_tendency(y=wm[48:56][[\"resultA\",\"resultB\"]].values,y_prob=probs)\n",
    "util.single_tendency(y=wm[56:60][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.multi_tendency(y=wm[56:60][[\"resultA\",\"resultB\"]].values,y_prob=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>tournament</th>\n",
       "      <th>gametype</th>\n",
       "      <th>teamA</th>\n",
       "      <th>teamidA</th>\n",
       "      <th>teamB</th>\n",
       "      <th>teamidB</th>\n",
       "      <th>resultA</th>\n",
       "      <th>resultB</th>\n",
       "      <th>addinfo</th>\n",
       "      <th>...</th>\n",
       "      <th>teamA_age</th>\n",
       "      <th>teamB_age</th>\n",
       "      <th>teamA_def_val</th>\n",
       "      <th>teamB_def_val</th>\n",
       "      <th>teamA_off_val</th>\n",
       "      <th>teamB_off_val</th>\n",
       "      <th>teamA_frag</th>\n",
       "      <th>teamB_frag</th>\n",
       "      <th>past_resultA</th>\n",
       "      <th>past_resultB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3062384</td>\n",
       "      <td>WM18</td>\n",
       "      <td>4</td>\n",
       "      <td>Brasilien</td>\n",
       "      <td>3439</td>\n",
       "      <td>Belgien</td>\n",
       "      <td>3382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.323929</td>\n",
       "      <td>0.529715</td>\n",
       "      <td>2.773791</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>3.733932</td>\n",
       "      <td>3.936808</td>\n",
       "      <td>-0.833325</td>\n",
       "      <td>0.588942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3061407</td>\n",
       "      <td>WM18</td>\n",
       "      <td>4</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3449</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>3377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725801</td>\n",
       "      <td>-0.832652</td>\n",
       "      <td>0.762350</td>\n",
       "      <td>4.990100</td>\n",
       "      <td>0.409147</td>\n",
       "      <td>4.501121</td>\n",
       "      <td>0.586074</td>\n",
       "      <td>-0.298047</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3061408</td>\n",
       "      <td>WM18</td>\n",
       "      <td>4</td>\n",
       "      <td>Russland</td>\n",
       "      <td>3448</td>\n",
       "      <td>Kroatien</td>\n",
       "      <td>3556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089528</td>\n",
       "      <td>0.672726</td>\n",
       "      <td>-0.342994</td>\n",
       "      <td>0.614451</td>\n",
       "      <td>-0.135983</td>\n",
       "      <td>1.243495</td>\n",
       "      <td>-1.684964</td>\n",
       "      <td>1.254183</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3062884</td>\n",
       "      <td>WM18</td>\n",
       "      <td>4</td>\n",
       "      <td>Schweden</td>\n",
       "      <td>3557</td>\n",
       "      <td>England</td>\n",
       "      <td>3299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>-0.644480</td>\n",
       "      <td>-0.252858</td>\n",
       "      <td>3.750675</td>\n",
       "      <td>-0.544408</td>\n",
       "      <td>3.765804</td>\n",
       "      <td>0.869954</td>\n",
       "      <td>-1.185036</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gameid tournament  gametype      teamA  teamidA       teamB  teamidB  \\\n",
       "56  3062384       WM18         4  Brasilien     3439     Belgien     3382   \n",
       "57  3061407       WM18         4    Uruguay     3449  Frankreich     3377   \n",
       "58  3061408       WM18         4   Russland     3448    Kroatien     3556   \n",
       "59  3062884       WM18         4   Schweden     3557     England     3299   \n",
       "\n",
       "    resultA  resultB addinfo      ...      teamA_age  teamB_age  \\\n",
       "56      1.0      2.0     NaN      ...       1.323929   0.529715   \n",
       "57      0.0      2.0     NaN      ...       0.725801  -0.832652   \n",
       "58      NaN      NaN     NaN      ...       1.089528   0.672726   \n",
       "59      0.0      2.0     NaN      ...       0.879375  -0.644480   \n",
       "\n",
       "    teamA_def_val  teamB_def_val  teamA_off_val  teamB_off_val  teamA_frag  \\\n",
       "56       2.773791       1.833333       3.733932       3.936808   -0.833325   \n",
       "57       0.762350       4.990100       0.409147       4.501121    0.586074   \n",
       "58      -0.342994       0.614451      -0.135983       1.243495   -1.684964   \n",
       "59      -0.252858       3.750675      -0.544408       3.765804    0.869954   \n",
       "\n",
       "    teamB_frag  past_resultA  past_resultB  \n",
       "56    0.588942          0.00          0.00  \n",
       "57   -0.298047          0.95          0.00  \n",
       "58    1.254183          0.95          2.85  \n",
       "59   -1.185036          3.90          2.05  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm[56:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
